[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The {traits.build} data standard, R package, and workflow",
    "section": "",
    "text": "1 About"
  },
  {
    "objectID": "index.html#brief-overview",
    "href": "index.html#brief-overview",
    "title": "The {traits.build} data standard, R package, and workflow",
    "section": "1.1 Brief overview",
    "text": "1.1 Brief overview\nImagine you wanted to build a database of plant traits. You might start by searching for existing datasets, but you’d quickly find that there are many different ways to names and ways to measure the same trait. You might also find that some datasets measure the same trait in different units, or use an outdated name for a species or taxon.\ntraits.build is a data standard, R package, and workflow that is desgined to help you build a harmonised, relational database from disparate datasets. The package was first developed to create austraits.build, an, open-source database of Australian plant traits. The code has been transformed into a standalone package allowing anyone to build a relational, tabular database for any taxonomic group and any collection of traits."
  },
  {
    "objectID": "index.html#about-this-manual",
    "href": "index.html#about-this-manual",
    "title": "The {traits.build} data standard, R package, and workflow",
    "section": "1.2 About this manual",
    "text": "1.2 About this manual\nThis manual is a step-by-step user guide to the traits.build standard, R package and workflow manual. Alongside this manual, you may find the following resources useful:\n\ninstallation instructions for the traits.build package\na reference page with all user-side functions for the traits.build package.\nlinks to example projects"
  },
  {
    "objectID": "index.html#a-simple-example",
    "href": "index.html#a-simple-example",
    "title": "The {traits.build} data standard, R package, and workflow",
    "section": "1.3 A simple example",
    "text": "1.3 A simple example\nTo get you started, we’ve provided a template example compilation which you can clone and modify. This provides the basic steps for building a traits.build compilation. Follow the instructions in Tutorials chapter for a step-by-step guide to building a database from scratch."
  },
  {
    "objectID": "index.html#getting-help",
    "href": "index.html#getting-help",
    "title": "The {traits.build} data standard, R package, and workflow",
    "section": "1.4 Getting help",
    "text": "1.4 Getting help\nAlong the way, users may encounter a number of errors and warnings. Some of these are designed to help you build a robust database, others may constitue an error in your data, file structure, or the package. If you encounter an error or warning, please read the message carefully and follow the instructions for getting help."
  },
  {
    "objectID": "index.html#contributing",
    "href": "index.html#contributing",
    "title": "The {traits.build} data standard, R package, and workflow",
    "section": "1.5 Contributing",
    "text": "1.5 Contributing\nXXX"
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "The {traits.build} data standard, R package, and workflow",
    "section": "1.6 Acknowledgements",
    "text": "1.6 Acknowledgements\nThis manual arose from code within the AusTraits project at https://github.com/traitecoevo/austraits.build. The AusTraits project received investment (https://doi.org/10.47486/DP720) from the Australian Research Data Commons (ARDC). The ARDC is funded by the National Collaborative Research Infrastructure Strategy (NCRIS)."
  },
  {
    "objectID": "motivation.html#the-problem",
    "href": "motivation.html#the-problem",
    "title": "2  Motivation",
    "section": "2.1 The problem",
    "text": "2.1 The problem\nEcological data are often collected in disparate formats, making it difficult to combine datasets for analysis. This is particularly true for trait data, which are often collected in a variety of formats and are rarely stored in a relational database. This makes it difficult to combine trait data with other ecological data, such as abundance or biomass, for analysis.\nMoreover, trait data are often collected in fragments, corrpesonding to scientific papers. Different traits may be collected for different species, or different traits are collected for the same species at different times or at different locations.\nTo create a large harmonised dataset, we need to combine these different datasets into a unfied whole, with common names, units, values for categorical traits, and so on. This is a time-consuming process.\n\nWe are not the first group to tackle this problem. Our field (plant ecology) has many trait datasets, most compiled from diverse sources. Most start small, with a few soruces that can be handled within a spreadhseet. But as thery grow, they ecnouter issues. The largest is TRY, with &gt; XXXX records from over. However, each group has had to tackle the compilation challenge anew, as there are no common pathways for creating a harmonised dataset."
  },
  {
    "objectID": "motivation.html#the-solution",
    "href": "motivation.html#the-solution",
    "title": "2  Motivation",
    "section": "2.2 The solution",
    "text": "2.2 The solution\nThe traits.build data standard, R package, and workflow offer a solution to this problem, with a set of open-source tools that enable users to create open-source, harmonised, reproducible databases from disparate datasets, underpinned by a sophisticated ontology able to handle the complexities inherent to ecological data.\nWe developed these tools for the to create AusTraits, an, open-source database of Australian plant traits. We figured others may want to replicate these efforts, so we the code and workflow was transformed into a standalone package allowing anyone to build a trait database for their own region or taxa.\nAlong the way, we hdeveloped a suite of tools:\n\ntraits.build data standard: a relational database structure that fully documents the contextual data essential to interpreting ecological data.\ntraits.build R package: a set of functions that enable users to create a harmonised database from disparate datasets.\nAPD: The AusTraits Plant Dictionary, with detailed descriptions for more than 500 plant trait concepts.\n\nAPCalign: an R package to align and update Australian plant taxon name strings with the Australian Plant Census.\n\nThe tools are open-source, so that users can apply them to suit their needs and without cost."
  },
  {
    "objectID": "workflow.html#core-principles",
    "href": "workflow.html#core-principles",
    "title": "3  Workflow",
    "section": "3.1 Core principles",
    "text": "3.1 Core principles\nThe project’s guiding principles are to:\n\nWherever possible solve problems in a general way, that enables others to leverage our efforts to solve their own problems.\nEnable users to create open-source, harmonised, reproducible databases from disparate datasets.\nProvide a fully transparent workflow, where all decisions on how to handle the data are exposed and can be.\nOffer a relational database structure that fully documents the contextual data essential to interpreting ecological data.\nOffer a straightforward, robust template for building a trait dictionary.\nOffer a database structure that is flexible enough to accommodate the complexities inherent to ecological data.\nOffer a database structure that is underlain by a documented ontology, ensuring each database field is interpretable and interoperable with other databases and data structures.\nHave no dependencies on proprietary software or costs to setup and maintain (beyoind person time)."
  },
  {
    "objectID": "workflow.html#approach",
    "href": "workflow.html#approach",
    "title": "3  Workflow",
    "section": "3.2 Approach",
    "text": "3.2 Approach\ntraits.build can be viewed through two lenses, its output structure and its underlying conceptual framework.\n\nOutput structure\ntraits.build is a relational database. There is a core traits table, supported by ancillary tables that document location properties (include latitude & longitude), context properties, dataset and measurement methods, taxon concepts, contributor details, and sources. All tables are stored in long format, such that there is a single column that includes all trait names (or location properties, or context properties) and column for trait values.\nA series of identifiers, including both textual fields (i.e. taxon_name, trait_name, dataset_id) and numeric identifiers link the ancillary tables to the traits table. The many numeric identifiers are overwhelming until you consider the conceptual framework, or mindmap, that underpins traits.build. They include: observation_id, population_id, individual_id, temporal_id, location_id, entity_context_id, plot_id, and source_id.\nStoring the resource as a relational table greatly reduces file sizes and facilitates searching for a particular metadata field\n\n\nConceptual framework\ntraits.build’s database structure effectively captures the complexities inherent to ecological data. Each dataset is unique, with measurements recorded on different entities (individuals, populations, species), in specific locations, and under countless environmental and experimental conditions, the so-called context of a measurement. The context offers essential meaning to each trait value. An ecological database must effectively capture all relevant contexts or the accompanying trait measurements lose much of their value.\ntraits.build is designed around the concept of an observation, a collection of measurements of different traits made at a specific point in time on a specific entity. OBOE, the Extensible Observation Ontology, first developed this conceptual framework, explicitly for complex ecological datasets. An observation_id links the measurements made on different traits that comprise a single observation. Measurements made at different points in time, on different entities, at different locations, or under different contextual conditions require unique observation_id values. The additional identifiers in the traits table (and the ancillary tables) were developed to ensure that unique observation_ids were generated for distinct observations, per this framework.\nWithin a dataset, observation_id’s are generated for unique combinations of the fields: taxon_name, population_id, individual_id, temporal_id, entity_type, and source_id. For instance, if measurements are made on the same individual during the wet versus dry season, the two observations will share an individual_id but have distinct temporal_id values, and therefore have distinct observation_id’s. See traits.build schema for definitions of identifiers"
  },
  {
    "objectID": "workflow.html#concepts",
    "href": "workflow.html#concepts",
    "title": "3  Workflow",
    "section": "3.3 Concepts",
    "text": "3.3 Concepts\nOur workflow is structured with the following concepts.\n\nData sources\nThe data in a traits.build compilation is derived from distinct sources, each contributed by an individual researcher, government entity (e.g. herbaria), or NGO. Each reflects the research agenda of the individual/organisation who contributed the data - the species selected, traits measured, manipulative treatments performed, and locations sampled encompass the diversity of research interests present in Australia throughout past decades. These datasets use different variable trait names, units and methods and have different data structures.\n\n\nStandardising and harmonising data\nTo create a single database for distribution to the research community, we developed a reproducible and transparent workflow in R for merging each dataset into AusTraits. The pipeline ensures the following information is standardised across all datasets in AusTraits. A metadata file for each study documents how the data tables submitted by an individual contributor are translated into the standardised terms used in the AusTraits database.\n\ntaxonomic nomenclature follows the Australian Plant Census (APC), with a pipeline to update outdated taxonomy, correct minor spelling mistakes, and align with a known genus when a full species names isn’t provided.\n\ntrait names are defined in our traits.yml file and only data for traits included in this file can be merged into AusTraits. The trait names used in the incoming dataset are mapped onto the appropriate AusTraits trait name.\nFor numeric traits the traits.yml file includes units and the allowable range of values. All incoming data are converted to the appropriate units and data outside the range of allowable values are removed from the main AusTraits data table.\nFor categorical traits the traits.yml file includes a list of allowable values, allowed terms for the trait. Each categorical trait value is defined in the traits.yml file. Lists of substitutions translate the exact syntax and terms in a submitted dataset into the values allowed by AusTraits. This ensures that for a certain trait the same value has an identical meaning throughout the AusTraits database.\nSite locations are recorded in decimal degrees.\n\n\n\nReferencing sources and recording methods\nThe metadata file also includes all metadata associated with the study:\n\nThe source information for each dataset is recorded. Most frequently, these are the primary publications derived from the dataset.\nPeople associated with the collection of the data are listed, including their role in the project.\nCollection methods are included.\nFields capture value type (mean, min, max, mode, range, bin) and associated replicate numbers, basis of value (measurement, expert_score, model_derived), entity type (species, population, individual), life stage (adult, juvenile,sapling, seedling), basis of record (field, field_experiment, preserved_specimen, captive_cultivated, lab, literature), and any additional measurement remarks.\nAvailable data on location properties are recorded.\nAvailable data on plot and treatment contextual properties are recorded.\nA context field, temporal_context_id, indicates if repeat measures were made on the same individual over time.\nA context field, method_context_id, indicates if the same trait was measured using multiple methods.\nCollection date is recorded.\n\n\n\nError checking\nWe consider deatiled error checking to be an inmporant and ongoing part of our workflow. The following steps are taken to ensure data quality.\n\nThe data curator can rus a series of tests on each data set, detailed in the adding data vignette\nThese tests identify misaligned units, unrecognised taxon names, and unsupported categorical trait values\nThese tests also identify and eliminate most duplicate data - instances where the same numeric trait data is submitted by multiple people\nEach dataset is then compiled into a report which summarises metadata and plots/charts trait values in comparison to other measurements of that trait in AusTraits. The report is reviewed by the data contributor to ensure metadata is complete and data values are as expected.\nA second member of the AusTraits team double checks each dataset before it is merged into the main repository."
  },
  {
    "objectID": "usage_examples.html#austraits",
    "href": "usage_examples.html#austraits",
    "title": "4  Usage examples",
    "section": "4.1 AusTraits",
    "text": "4.1 AusTraits\nThe workflow described here evolved out of the AusTraits project. AusTraits is an open-source, harmonized database of Australian plant trait data. It synthesises data on nearly 500 traits across more than 30,000 taxa from over 300 sources. Begun in 2016 as an initiative between three lab groups, it has grown to be the largest collation of plant trait data for Australian plants.\nThe traits.build workflow is used to build the AusTraits database. The workflow XXXX"
  },
  {
    "objectID": "usage_examples.html#other-examples",
    "href": "usage_examples.html#other-examples",
    "title": "4  Usage examples",
    "section": "4.2 Other examples",
    "text": "4.2 Other examples\nThere are now multiple new porjects using the traits.build workflow and package. At this stage, most are in private repositories, but we envisage that they will be made public in the near future.\n\nAusTraits: A compilation of traits data for Australian plants\nAusInverTraits: A compilation of traits data for invertebrates, led by Inverterbates Australia\nAusFizz: A compilation of physiological response curves for plants"
  },
  {
    "objectID": "long_wide.html#background",
    "href": "long_wide.html#background",
    "title": "5  Long vs Wide data",
    "section": "5.1 Background",
    "text": "5.1 Background\n\nEase of use (manipulation & analysis)\nSize of data product: storage costs, speed of loading, transfer\n\nConcepts\n\nLong data\nWide data\nTidy data"
  },
  {
    "objectID": "long_wide.html#our-approach",
    "href": "long_wide.html#our-approach",
    "title": "5  Long vs Wide data",
    "section": "5.2 Our approach",
    "text": "5.2 Our approach\n\nMultiple products available\n\n\nPivotting between long and wide"
  },
  {
    "objectID": "database_standard.html",
    "href": "database_standard.html",
    "title": "6  Data standard",
    "section": "",
    "text": "XXX Describe the emerhign traits.build data standard"
  },
  {
    "objectID": "database_structure.html",
    "href": "database_structure.html",
    "title": "7  Data structure",
    "section": "",
    "text": "8 Components\nThe core components are defined as follows."
  },
  {
    "objectID": "database_structure.html#traits",
    "href": "database_structure.html#traits",
    "title": "7  Data structure",
    "section": "8.1 traits",
    "text": "8.1 traits\nDescription: A table containing measurements of traits.\nContent:\n\n\n\n\n\nkey\n\n\nvalue\n\n\n\n\n\n\ndataset_id\n\n\nPrimary identifier for each study contributed to AusTraits; most often these are scientific papers, books, or online resources. By default this should be the name of the first author and year of publication, e.g. Falster_2005.\n\n\n\n\ntaxon_name\n\n\nScientific name of the taxon on which traits were sampled, without authorship. When possible, this is the currently accepted (botanical) or valid (zoological) scientific name, but might also be a higher taxonomic level.\n\n\n\n\nobservation_id\n\n\nA unique integral identifier for the observation, where an observation is all measurements made on an individual at a single point in time. It is important for joining traits coming from the same observation_id. Within each dataset, observation_id’s are unique combinations of taxon_name, population_id, individual_id, and temporal_context_id.\n\n\n\n\ntrait_name\n\n\nName of the trait sampled. Allowable values specified in the table definitions.\n\n\n\n\nvalue\n\n\nThe measured value of a trait, location property or context property.\n\n\n\n\nunit\n\n\nUnits of the sampled trait value after aligning with AusTraits standards.\n\n\n\n\nentity_type\n\n\nA categorical variable specifying the entity corresponding to the trait values recorded.\n\n\n\n\nvalue_type\n\n\nA categorical variable describing the statistical nature of the trait value recorded.\n\n\n\n\nbasis_of_value\n\n\nA categorical variable describing how the trait value was obtained.\n\n\n\n\nreplicates\n\n\nNumber of replicate measurements that comprise a recorded trait measurement. A numeric value (or range) is ideal and appropriate if the value type is a mean, median, min or max. For these value types, if replication is unknown the entry should be unknown. If the value type is raw_value the replicate value should be 1. If the trait is categorical or the value indicates a measurement for an entire species (or other taxon) replicate value should be .na.\n\n\n\n\nbasis_of_record\n\n\nA categorical variable specifying from which kind of specimen traits were recorded.\n\n\n\n\nlife_stage\n\n\nA field to indicate the life stage or age class of the entity measured. Standard values are adult, sapling, seedling and juvenile.\n\n\n\n\npopulation_id\n\n\nA unique integer identifier for a population, where a population is defined as individuals growing in the same location (location_id /location_name) and plot (plot_context_id, a context category) and being subjected to the same treatment (treatment_context_id, a context category).\n\n\n\n\nindividual_id\n\n\nA unique integer identifier for an individual, with individuals numbered sequentially within each dataset by taxon by population grouping. Most often each row of data represents an individual, but in some datasets trait data collected on a single individual is presented across multiple rows of data, such as if the same trait is measured using different methods or the same individual is measured repeatedly across time.\n\n\n\n\nrepeat_measurements_id\n\n\nA unique integer identifier for repeat measurements of a trait that comprise a single observation, such as a response curve.\n\n\n\n\ntemporal_context_id\n\n\nA unique integer identifier assigned where repeat observations are made on the same individual (or population, or taxon) across time. The identifier links to specific information in the context table.\n\n\n\n\nsource_id\n\n\nFor datasets that are compilations, an identifier for the original data source.\n\n\n\n\nlocation_id\n\n\nA unique integer identifier for a location, with locations numbered sequentially within a dataset. The identifier links to specific information in the location table.\n\n\n\n\nentity_context_id\n\n\nA unique integer identifier indicating specific contextual properties of an individual, possibly including the individual’s sex or caste (for social insects).\n\n\n\n\nplot_context_id\n\n\nA unique integer identifier for a plot, where a plot is a distinct collection of organisms within a single geographic location, such as plants growing on different aspects or blocks in an experiment. The identifier links to specific information in the context table.\n\n\n\n\ntreatment_context_id\n\n\nA unique integer identifier for a treatment, where a treatment is any experimental manipulation to an organism’s growing/living conditions. The identifier links to specific information in the context table.\n\n\n\n\ncollection_date\n\n\nDate sample was taken, in the format yyyy-mm-dd, yyyy-mm or yyyy, depending on the resoluton specified. Alternatively an overall range for the study can be indicating, with the starting and ending sample date sepatated by a /, as in 2010-10/2011-03\n\n\n\n\nmeasurement_remarks\n\n\nBrief comments or notes accompanying the trait measurement.\n\n\n\n\nmethod_id\n\n\nA unique integer identifier to distinguish between multiple sets of methods used to measure a single trait within the same dataset. The identifier links to specific information in the methods table.\n\n\n\n\nmethod_context_id\n\n\nA unique integer identifier indicating a trait is measured multiple times on the same entity, with different methods used for each entry. This field is only used if a single trait is measured using multiple methods within the same dataset. The identifier links to specific information in the context table.\n\n\n\n\noriginal_name\n\n\nName given to taxon in the original data supplied by the authors.\n\n\n\n\n\n\nEntity type\nAn entity is the feature of interest, indicating what a trait value applies to. While an entity can be just a component of an organism, within the scope of AusTraits, an individual is the finest scale entity that can be documented. The same study might measure some traits at a population-level (entity = population) and others at an individual-level (entity = individual).\nIn detail:\n\nentity_type is a categorical variable specifying the entity corresponding to the trait values recorded. Possible values are:\n\n\n\n\n\n\nkey\n\n\nvalue\n\n\n\n\n\n\nindividual\n\n\nValue comes from a single individual.\n\n\n\n\npopulation\n\n\nValue represents a summary statistic from multiple individuals at a single location.\n\n\n\n\nmetapopulation\n\n\nValue represents a summary statistic from individuals of the taxon across multiple locations.\n\n\n\n\nspecies\n\n\nValue represents a summary statistic for a species or infraspecific taxon across its range or as estimated by an expert based on their knowledge of the taxon. Data fitting this category include estimates from reference books that represent a taxon’s entire range and values for categorical variables obtained from a reference book or identified by an expert.\n\n\n\n\ngenus\n\n\nValue represents a summary statistic or expert score for an entire genus.\n\n\n\n\nfamily\n\n\nValue represents a summary statistic or expert score for an entire family.\n\n\n\n\norder\n\n\nValue represents a summary statistic or expert score for an entire order.\n\n\n\n\n\n\n\nIdentifiers\nThe traits table includes 12 identifiers, dataset_id, observation_id, taxon_name, population_id, individual_id, temporal_context_id, source_id, location_id, entity_context_id, plot_context_id, treatment_context_id, and method_context_id.\ndataset_id, source_id and taxon_name have easy-to-interpret values. The others are simply integral identifiers that link groups of measurements and are automatically generated through the AusTraits workflow (individual_id can be assigned in the metadata file or automatically generated.)\nTo expand on the definitions provided above,\n\nobservation_id links measurements made on the same entity (individual, population, or species) at a single point in time.\npopulation_id indicates entites that share a common location_id, plot_context_id, and treatment_context_id. It is used to align measurements and observation_id’s for individuals versus populations (i.e. distinct entity_types) that share a common population_id. It is numbered sequentially within a dataset.\nindividual_id indicates a unique organisms. It is numbered sequentially within a dataset by population. Multiple observations on the same organism across time (with distinct observation_id values), share a common individual_id.\ntemporal_context_id indicates a distinct point in time and is used only if there are repeat measurements on a population or individual across time. The identifier links to context properties (& their associated information) in the contexts table for context properties of type temporal.\nsource_id is applied if not all data within a single dataset (dataset_id) is from the same source, such as when a dataset represents a compilation for a meta-analysis.\nlocation_id links to a distinct location_name and associated location_properties in the location table.\nentity_context_id links to information in the contexts table for context properties (& associated values/descriptions) with category entity_context. Entity_contexts include organism sex, organism caste and any other features of an entity that needs to be documented.\nplot_context_id links to information in the contexts table for context properties (& associated values/descriptions) with category plot. Plot contexts include both blocks/plots within an experimental design as well as any stratified variation within a location that needs to be documented (e.g. slope position).\ntreatment_context_idlinks to information in the contexts table for context properties (& associated values/descriptions) with category treatment. Treatment contexts are experimental manipulations applied to groups of individuals.\nmethod_context_idlinks to information in the contexts table for context properties (& associated values/descriptions) with category method. A method context indicates that the same trait was measured on or across individuals using different methods.\n\nAs well, measurement_remarks is used to document brief comments or notes accompanying the trait measurement.\n\n\nLife stage, basis of record\n\nlife_stage is a field to indicate the life stage or age class of the entity measured. standard values are adult, sapling, seedling and juvenile..\nbasis_of_record is a categorical variable specifying from which kind of specimen traits were recorded. Possible values are:\n\n\n\n\n\n\nkey\n\n\nvalue\n\n\n\n\n\n\nfield\n\n\nTraits were recorded on entities living naturally in the field.\n\n\n\n\nfield_experiment\n\n\nTraits were recorded on entities living under experimentally manipulated conditions in the field.\n\n\n\n\ncaptive_cultivated\n\n\nTraits were recorded on entities living in a common garden, arboretum, or botanical or zoological garden.\n\n\n\n\nlab\n\n\nTraits were recorded on entities growing in a lab, glasshouse or growth chamber.\n\n\n\n\npreserved_specimen\n\n\nTraits were recorded from specimens preserved in a collection, eg. herbarium or museum\n\n\n\n\nliterature\n\n\nTraits were sourced from values reported in the literature, and where the basis of record is not otherwise known.\n\n\n\n\n\n\n\nValues, Value types, basis of value\nEach record in the table of trait data has an associated value, value_type, and basis_of_value.\nValue type: A trait’s value_type is either numeric or categorical. - For traits with numerical values, the recorded value has been converted into standardised units and the AusTraits workflow has confirmed the value can be converted into a number and lies within the allowable range. - For categorical variables, records have been aligned through substitutions to values listed as allowable values (terms) in a trait’s definition. * we use _ for multi-word terms, e.g. semi_deciduous\n* we use a space for situations where two values co-occur for the same entity. For instance, a flora might indicate that a plant species can be either annual or biennial, in which case the trait is scored as annual biennial.\nEach trait measurement has an associated value_type, which is a categorical variable describing the statistical nature of the trait value recorded. Possible values are:\n\n\n\n\n\nkey\n\n\nvalue\n\n\n\n\n\n\nraw\n\n\nValue recorded for an entity.\n\n\n\n\nminimum\n\n\nValue is the minimum of values recorded for an entity.\n\n\n\n\nmean\n\n\nValue is the mean of values recorded for an entity.\n\n\n\n\nmedian\n\n\nValue is the median of values recorded for an entity.\n\n\n\n\nmaximum\n\n\nValue is the maximum of values recorded for an entity.\n\n\n\n\nmode\n\n\nValue is the mode of values recorded for an entity. This is the appropriate value type for a categorical trait value.\n\n\n\n\nrange\n\n\nValue is a range of values recorded for an entity.\n\n\n\n\nbin\n\n\nValue for an entity falls within specified limits.\n\n\n\n\nunknown\n\n\nNot currently known.\n\n\n\n\n\nEach trait measurement also has an associated basis_of_value, which is a categorical variable describing how the trait value was obtained. Possible values are:\n\n\n\n\n\nkey\n\n\nvalue\n\n\n\n\n\n\nmeasurement\n\n\nValue is the result of a measurement(s) made on a specimen(s).\n\n\n\n\nexpert_score\n\n\nValue has been estimated by an expert based on their knowledge of the entity.\n\n\n\n\nmodel_derived\n\n\nValue is derived from a statistical model, for example via gap-filling.\n\n\n\n\nunknown\n\n\nNot currently known.\n\n\n\n\n\nAusTraits does not include intra-individual observations made at a single point in time. When multiple measurements per individual are submitted to AusTraits, we take the mean of the values and record the value_type as mean and indicate under replicates the number of measurements made."
  },
  {
    "objectID": "database_structure.html#locations",
    "href": "database_structure.html#locations",
    "title": "7  Data structure",
    "section": "8.2 locations",
    "text": "8.2 locations\nDescription: A table containing observations of location/site characteristics associated with information in traits. Cross referencing between the two dataframes is possible using combinations of the variables dataset_id, location_name.\nContent:\n\n\n\n\n\nkey\n\n\nvalue\n\n\n\n\n\n\ndataset_id\n\n\nPrimary identifier for each study contributed to AusTraits; most often these are scientific papers, books, or online resources. By default this should be the name of the first author and year of publication, e.g. Falster_2005.\n\n\n\n\nlocation_id\n\n\nA unique integer identifier for a location, with locations numbered sequentially within a dataset. The identifier links to specific information in the location table.\n\n\n\n\nlocation_name\n\n\nlocation name\n\n\n\n\nlocation_property\n\n\nThe location characteristic being recorded. The name should include units of measurement, e.g. MAT (C). Ideally we have at least the following variables for each location, longitude (deg), latitude (deg), description.\n\n\n\n\nvalue\n\n\nThe measured value of a location property."
  },
  {
    "objectID": "database_structure.html#contexts",
    "href": "database_structure.html#contexts",
    "title": "7  Data structure",
    "section": "8.3 contexts",
    "text": "8.3 contexts\nDescription: A table containing observations of contextual characteristics associated with information in traits. Cross referencing between the two dataframes is possible using combinations of the variables dataset_id, link_id, and link_vals.\nContent:\n\n\n\n\n\nkey\n\n\nvalue\n\n\n\n\n\n\ndataset_id\n\n\nPrimary identifier for each study contributed to AusTraits; most often these are scientific papers, books, or online resources. By default this should be the name of the first author and year of publication, e.g. Falster_2005.\n\n\n\n\ncontext_property\n\n\nThe contextual characteristic being recorded. If applicable, name should include units of measurement, e.g. CO2 concentration (ppm).\n\n\n\n\ncategory\n\n\nThe category of context property, with options being plot, treatment, individual_context, temporal and method.\n\n\n\n\nvalue\n\n\nThe measured value of a context property.\n\n\n\n\ndescription\n\n\nDescription of a specific context property value.\n\n\n\n\nlink_id\n\n\nVariable indicating which identifier column in the traits table contains the specified link_vals.\n\n\n\n\nlink_vals\n\n\nUnique integer identifiers that link between identifier columns in the traits table and the contextual properties/values in the contexts table."
  },
  {
    "objectID": "database_structure.html#methods",
    "href": "database_structure.html#methods",
    "title": "7  Data structure",
    "section": "8.4 methods",
    "text": "8.4 methods\nDescription: A table containing details on methods with which data were collected, including time frame and source. Cross referencing with the traits table is possible using combinations of the variables dataset_id, trait_name.\nContent:\n\n\n\n\n\nkey\n\n\nvalue\n\n\n\n\n\n\ndataset_id\n\n\nPrimary identifier for each study contributed to AusTraits; most often these are scientific papers, books, or online resources. By default this should be the name of the first author and year of publication, e.g. Falster_2005.\n\n\n\n\ntrait_name\n\n\nName of the trait sampled. Allowable values specified in the table definitions.\n\n\n\n\nmethods\n\n\nA textual description of the methods used to collect the trait data. Whenever available, methods are taken near-verbatim from the referenced source. Methods can include descriptions such as ‘measured on botanical collections’, ‘data from the literature’, or a detailed description of the field or lab methods used to collect the data.\n\n\n\n\nmethod_id\n\n\nA unique integer identifier to distinguish between multiple sets of methods used to measure a single trait within the same dataset. The identifier links to specific information in the methods table.\n\n\n\n\ndescription\n\n\nA 1-2 sentence description of the purpose of the study.\n\n\n\n\nsampling_strategy\n\n\nA written description of how study locations were selected and how study individuals were selected. When available, this information is lifted verbatim from a published manuscript. For preserved specimens, this field ideally indicates which records were ‘sampled’ to measure a specific trait.\n\n\n\n\nsource_primary_key\n\n\nCitation key for the primary source in sources. The key is typically formatted as Surname_year.\n\n\n\n\nsource_primary_citation\n\n\nCitation for the primary source. This detail is generated from the primary source in the metadata.\n\n\n\n\nsource_secondary_key\n\n\nCitation key for the secondary source in sources. The key is typically formatted as Surname_year.\n\n\n\n\nsource_secondary_citation\n\n\nCitations for the secondary source. This detail is generated from the secondary source in the metadata.\n\n\n\n\nsource_original_dataset_key\n\n\nCitation key for the original dataset_id in sources; for compilations. The key is typically formatted as Surname_year.\n\n\n\n\nsource_original_dataset_citation\n\n\nCitations for the original dataset_id in sources; for compilationse. This detail is generated from the original source in the metadata.\n\n\n\n\ndata_collectors\n\n\nThe person (people) leading data collection for this study.\n\n\n\n\nassistants\n\n\nNames of additional people who played a more minor role in data collection for the study.\n\n\n\n\ndataset_curators\n\n\nNames of AusTraits team member(s) who contacted the data collectors and added the study to the AusTraits repository."
  },
  {
    "objectID": "database_structure.html#excluded_data",
    "href": "database_structure.html#excluded_data",
    "title": "7  Data structure",
    "section": "8.5 Excluded_data",
    "text": "8.5 Excluded_data\nDescription: A table of data that did not pass quality tests and so were excluded from the master dataset. The structure is identical to that presented in the traits table, only with an extra column called error indicating why the record was excluded. Common reasons are missing_unit_conversions, missing_value, and unsupported_trait_value.\nContent:\n\n\n\n\n\nkey\n\n\nvalue\n\n\n\n\n\n\nerror\n\n\nIndicating why the record was excluded. Common reasons are missing_unit_conversions, missing_value, and unsupported_trait_value.\n\n\n\n\ndataset_id\n\n\nPrimary identifier for each study contributed to AusTraits; most often these are scientific papers, books, or online resources. By default this should be the name of the first author and year of publication, e.g. Falster_2005.\n\n\n\n\ntaxon_name\n\n\nScientific name of the taxon on which traits were sampled, without authorship. When possible, this is the currently accepted (botanical) or valid (zoological) scientific name, but might also be a higher taxonomic level.\n\n\n\n\nobservation_id\n\n\nA unique integral identifier for the observation, where an observation is all measurements made on an individual at a single point in time. It is important for joining traits coming from the same observation_id. Within each dataset, observation_id’s are unique combinations of taxon_name, population_id, individual_id, and temporal_context_id.\n\n\n\n\ntrait_name\n\n\nName of the trait sampled. Allowable values specified in the table definitions.\n\n\n\n\nvalue\n\n\nThe measured value of a trait.\n\n\n\n\nunit\n\n\nUnits of the sampled trait value after aligning with AusTraits standards.\n\n\n\n\nentity_type\n\n\nA categorical variable specifying the entity corresponding to the trait values recorded.\n\n\n\n\nvalue_type\n\n\nA categorical variable describing the statistical nature of the trait value recorded.\n\n\n\n\nbasis_of_value\n\n\nA categorical variable describing how the trait value was obtained.\n\n\n\n\nreplicates\n\n\nNumber of replicate measurements that comprise a recorded trait measurement. A numeric value (or range) is ideal and appropriate if the value type is a mean, median, min or max. For these value types, if replication is unknown the entry should be unknown. If the value type is raw_value the replicate value should be 1. If the trait is categorical or the value indicates a measurement for an entire species (or other taxon) replicate value should be .na.\n\n\n\n\nbasis_of_record\n\n\nA categorical variable specifying from which kind of specimen traits were recorded.\n\n\n\n\nlife_stage\n\n\nA field to indicate the life stage or age class of the entity measured. Standard values are adult, sapling, seedling and juvenile.\n\n\n\n\npopulation_id\n\n\nA unique integer identifier for a population, where a population is defined as individuals growing in the same location (location_id /location_name) and plot (plot_context_id, a context category) and being subjected to the same treatment (treatment_context_id, a context category).\n\n\n\n\nindividual_id\n\n\nA unique integer identifier for an individual, with individuals numbered sequentially within each dataset by taxon by population grouping. Most often each row of data represents an individual, but in some datasets trait data collected on a single individual is presented across multiple rows of data, such as if the same trait is measured using different methods or the same individual is measured repeatedly across time.\n\n\n\n\nrepeat_measurements_id\n\n\nA unique integer identifier for repeat measurements of a trait that comprise a single observation, such as a response curve.\n\n\n\n\ntemporal_context_id\n\n\nA unique integer identifier assigned where repeat observations are made on the same individual (or population, or taxon) across time. The identifier links to specific information in the context table.\n\n\n\n\nsource_id\n\n\nFor datasets that are compilations, an identifier for the original data source.\n\n\n\n\nlocation_id\n\n\nA unique integer identifier for a location, with locations numbered sequentially within a dataset. The identifier links to specific information in the location table.\n\n\n\n\nentity_context_id\n\n\nA unique integer identifier indicating specific contextual properties of an individual, possibly including the individual’s sex or caste (for social insects).\n\n\n\n\nplot_context_id\n\n\nA unique integer identifier for a plot, where a plot is a distinct collection of organisms within a single geographic location, such as plants growing on different aspects or blocks in an experiment. The identifier links to specific information in the context table.\n\n\n\n\ntreatment_context_id\n\n\nA unique integer identifier for a treatment, where a treatment is any experimental manipulation to an organism’s growing/living conditions. The identifier links to specific information in the context table.\n\n\n\n\ncollection_date\n\n\nDate sample was taken, in the format yyyy-mm-dd, yyyy-mm or yyyy, depending on the resoluton specified. Alternatively an overall range for the study can be indicating, with the starting and ending sample date sepatated by a /, as in 2010-10/2011-03\n\n\n\n\nmeasurement_remarks\n\n\nBrief comments or notes accompanying the trait measurement.\n\n\n\n\nmethod_id\n\n\nA unique integer identifier to distinguish between multiple sets of methods used to measure a single trait within the same dataset. The identifier links to specific information in the methods table.\n\n\n\n\nmethod_context_id\n\n\nA unique integer identifier indicating a trait is measured multiple times on the same entity, with different methods used for each entry. This field is only used if a single trait is measured using multiple methods within the same dataset. The identifier links to specific information in the context table.\n\n\n\n\noriginal_name\n\n\nName given to taxon in the original data supplied by the authors."
  },
  {
    "objectID": "database_structure.html#taxa",
    "href": "database_structure.html#taxa",
    "title": "7  Data structure",
    "section": "8.6 taxa",
    "text": "8.6 taxa\nDescription: A table containing details on taxa that are included in the table traits. We have attempted to align species names with known taxonomic units in the Australian Plant Census (APC) and/or the Australian Plant Names Index (APNI); the sourced information is released under a CC-BY3 license.\nVersion 0.1.0 of AusTraits contains records for 1255 different taxa.\nContent:\n\n\n\n\n\nkey\n\n\nvalue\n\n\n\n\n\n\ntaxon_name\n\n\nScientific name of the taxon on which traits were sampled, without authorship. When possible, this is the currently accepted (botanical) or valid (zoological) scientific name, but might also be a higher taxonomic level.\n\n\n\n\ntaxonomic_reference\n\n\nName of the taxonomy (tree) that contains this concept. ie. APC, AusMoss etc.\n\n\n\n\ntaxon_rank\n\n\nThe taxonomic rank of the most specific name in the scientific name.\n\n\n\n\ntrinomial\n\n\nThe infraspecific taxon name match for an original name. This column is assigned na for taxon name that are at a broader taxonomic_resolution.\n\n\n\n\nbinomial\n\n\nThe species-level taxon name match for an original name. This column is assigned na for taxon name that are at a broader taxonomic_resolution.\n\n\n\n\ngenus\n\n\nGenus of the taxon without authorship.\n\n\n\n\nfamily\n\n\nFamily of the taxon.\n\n\n\n\ntaxon_distribution\n\n\nKnown distribution of the taxon, by Australian state.\n\n\n\n\nestablishment_means\n\n\nStatement about whether an organism or organisms have been introduced to a given place and time through the direct or indirect activity of modern humans.\n\n\n\n\ntaxonomic_status\n\n\nThe status of the use of the scientificName as a label for the taxon in regard to the ‘accepted (or valid) taxonomy’. The assigned taxonomic status must be linked to a specific taxonomic reference that defines the concept.\n\n\n\n\nscientific_name\n\n\nThe full scientific name, with authorship and date information if known.\n\n\n\n\nscientific_name_authorship\n\n\nThe authorship information for the scientific name formatted according to the conventions of the applicable.\n\n\n\n\ntaxon_id\n\n\nAn identifier for the set of taxon information (data associated with the taxon class). May be a global unique identifier or an identifier specific to the data set. Must be resolvable within this dataset.\n\n\n\n\nscientific_name_id\n\n\nAn identifier for the set of taxon information (data associated with the taxon class). May be a global unique identifier or an identifier specific to the data set. Must be resolvable within this dataset."
  },
  {
    "objectID": "database_structure.html#taxonomic_updates",
    "href": "database_structure.html#taxonomic_updates",
    "title": "7  Data structure",
    "section": "8.7 taxonomic_updates",
    "text": "8.7 taxonomic_updates\nDescription: A table of all taxonomic changes implemented in the construction of AusTraits. Changes are determined by comparing the originally submitted taxon name against the taxonomic names listed in the taxonomic reference files, best placed in a subfolder in the config folder . Cross referencing with the traits table is possible using combinations of the variables dataset_id and taxon_name.\nContent:\n\n\n\n\n\nkey\n\n\nvalue\n\n\n\n\n\n\ndataset_id\n\n\nPrimary identifier for each study contributed to AusTraits; most often these are scientific papers, books, or online resources. By default this should be the name of the first author and year of publication, e.g. Falster_2005.\n\n\n\n\noriginal_name\n\n\nName given to taxon in the original data supplied by the authors.\n\n\n\n\ncleaned_name\n\n\nThe taxon name without authorship after implementing automated syntax standardisation and spelling changes as well as manually encoded syntax alignments for this taxon in the metadata file for the corresponding dataset_id. This name has not yet been matched to the currently accepted (botanical) or valid (zoological) taxon name in cases where there are taxonomic synonyms, isonyms, orthographic variants, etc.\n\n\n\n\ntaxonomic_resolution\n\n\nThe rank of the most specific taxon name (or scientific name) to which a submitted orignal name resolves.\n\n\n\n\ncleaned_scientific_name_id\n\n\nAn identifier for the cleaned name before it is updated to the currently accepted name usage. This may be a global unique identifier or an identifier specific to the data set. Must be resolvable within this dataset.\n\n\n\n\ncleaned_name_taxonomic_status\n\n\nThe status of the use of the cleaned_name as a label for a taxon. Requires taxonomic opinion to define the scope of a taxon. Rules of priority then are used to define the taxonomic status of the nomenclature contained in that scope, combined with the experts opinion. It must be linked to a specific taxonomic reference that defines the concept.\n\n\n\n\ncleaned_name_alternative_taxonomic_status\n\n\nThe taxonomic status of alternative taxonomic records with cleaned_name as the accepted (botanical) or valid (zoological) taxon name.\n\n\n\n\ntaxon_id\n\n\nAn identifier for the set of taxon information (data associated with the taxon class). May be a global unique identifier or an identifier specific to the data set. Must be resolvable within this dataset.\n\n\n\n\ntaxon_name\n\n\nScientific name of the taxon on which traits were sampled, without authorship. When possible, this is the currently accepted (botanical) or valid (zoological) scientific name, but might also be a higher taxonomic level.\n\n\n\n\n\nBoth the original and the updated taxon names are included in the traits table."
  },
  {
    "objectID": "database_structure.html#definitions",
    "href": "database_structure.html#definitions",
    "title": "7  Data structure",
    "section": "8.8 definitions",
    "text": "8.8 definitions\nDescription: A copy of the definitions for all tables and terms. Information included here was used to process data and generate any documentation for the study.\nDetails on trait definitions: The allowable trait names and trait values are defined in the definitions file. Each trait is labelled as either numeric or categorical. An example of each type is as follows. For an example, see the the Trait definitions for AusTraits.\nleaf_mass_per_area\n\nnumber of records: 0\nnumber of studies: 0\n\nwoodiness\n\nnumber of records: 0\nnumber of studies: 0"
  },
  {
    "objectID": "database_structure.html#contributors",
    "href": "database_structure.html#contributors",
    "title": "7  Data structure",
    "section": "8.9 contributors",
    "text": "8.9 contributors\nDescription: A table of people contributing to each study.\nContent:\n\n\n\n\n\nkey\n\n\nvalue\n\n\n\n\n\n\ndataset_id\n\n\nPrimary identifier for each study contributed to AusTraits; most often these are scientific papers, books, or online resources. By default this should be the name of the first author and year of publication, e.g. Falster_2005.\n\n\n\n\nlast_name\n\n\nLast name of the data collector.\n\n\n\n\ngiven_name\n\n\nGiven names of the data collector.\n\n\n\n\nORCID\n\n\nORCID of the data collector.\n\n\n\n\naffiliation\n\n\nLast known institution or affiliation.\n\n\n\n\nadditional_role\n\n\nAdditional roles of data collector, mostly contact person."
  },
  {
    "objectID": "database_structure.html#sources",
    "href": "database_structure.html#sources",
    "title": "7  Data structure",
    "section": "8.10 sources",
    "text": "8.10 sources\nFor each dataset in the compilation there is the option to list primary and secondary citations. The primary citation is defined as, The secondary citation is defined as,\nThe element sources includes bibtex versions of all sources which can be imported into your reference library:\nRefManageR::WriteBib(austraits$sources, \"refs.bib\") # write all sources to file\nRefManageR::WriteBib(austraits$sources[\"Falster_2005_1\"], \"refs.bib\") # write a single reference to a file\nOr individually viewed:\naustraits$sources[\"Falster_2005_1\"]\nA formatted version of the sources also exists within the table methods."
  },
  {
    "objectID": "database_structure.html#metadata",
    "href": "database_structure.html#metadata",
    "title": "7  Data structure",
    "section": "8.11 metadata",
    "text": "8.11 metadata\nDescription: Metadata associated with the dataset, including title, creators, license, subject, funding sources."
  },
  {
    "objectID": "database_structure.html#build_info",
    "href": "database_structure.html#build_info",
    "title": "7  Data structure",
    "section": "8.12 build_info",
    "text": "8.12 build_info\nDescription: A description of the computing environment used to create this version of the dataset, including version number, git commit and R session_info."
  },
  {
    "objectID": "dictionary.html",
    "href": "dictionary.html",
    "title": "8  Trait dictionary",
    "section": "",
    "text": "XXX"
  },
  {
    "objectID": "traits_build.html",
    "href": "traits_build.html",
    "title": "9  The package",
    "section": "",
    "text": "The traits.build package provides functions needed to build a compilation from sources to the standards specified\nXXXX"
  },
  {
    "objectID": "file_organisation.html#repository-structure",
    "href": "file_organisation.html#repository-structure",
    "title": "10  File organisation",
    "section": "10.1 Repository structure",
    "text": "10.1 Repository structure\nThe main directory for the austraits.build repository contains the following files and folders, with purpose as indicated. Not all of these files are required for a compilation, some are used for extra features such as website. They are included here for completeness.\nFiles used for data compilation\n├── remake.yml/build.R    # instructions for build\n├── config                # configuration files\n├── data                  # raw data files\n├── R                     # folder with custom functions\n├── export                # folder for output\n└── scripts               # scripts for processing files before/after build\nR project file\n├── traits.build.Rproj     # Rstudio project\nFiles for maintaining a repo on github\n├── README.md         # landing page\n├── .github           # folder containing github actions, issue templates, code of conduct\n├── LICENCE\n├── NEWS.md\n├── _pkgdown.yml      # used to create packagedown website\n├── docs              # contains website\n├── Dockerfile        # creates an image of R environment used in build\nFiles used for creation of R package for this compilation\nXXX Explan this more\n├── NAMESPACE             # functions being exported\n├── DESCRIPTION           # R package description\n├── tests                 # defines tests applied to datasets\n├── vignettes             # documentation of repo file structure, AusTraits database structure, definitions, data input processes"
  },
  {
    "objectID": "file_organisation.html#config-folder",
    "href": "file_organisation.html#config-folder",
    "title": "10  File organisation",
    "section": "10.2 /config folder",
    "text": "10.2 /config folder\nThe folder config contains four files which govern the building of the dataset.\nconfig\n├── metadata.yml\n├── traits.yml\n├── taxon_list.csv\n└── unit_conversions.csv\n\nmetadata.yml\nXXX\n\n\ntraits.yml\nThe file traits.yml provides the trait definitions used to compile AusTraits, including allowable trait values. The trait definitions are fully described in an additional vignette. A .yml file is a structured data file where information is presented in a hierarchical format (see appendix for details).\n\n\ntaxon_list.csv\nThe file taxon_list.csv is our master list of known taxa.\nXXX Explan this more. Only show essential variables in table below.\n\n\n\n\n\n\n\ntaxon_name\nfamily\nscientific_name_authorship\ntaxonomic_reference\ncleaned_name_taxonomic_status\ncleaned_scientific_name_id\n\n\n\n\nAbelia x grandiflora\nCaprifoliaceae\n(Rovelli ex AndrÃ©) Rehder\nAPC\naccepted\nhttps://id.biodiversity.org.au/name/apni/190758\n\n\nAbelmoschus ficulneus\nMalvaceae\n(L.) Wight\nAPC\naccepted\nhttps://id.biodiversity.org.au/name/apni/55929\n\n\nAbelmoschus manihot\nMalvaceae\n(L.) Medik.\nAPC\naccepted\nhttps://id.biodiversity.org.au/name/apni/55937\n\n\nAbelmoschus manihot subsp. manihot\nMalvaceae\nNA\nAPC\naccepted\nhttps://id.biodiversity.org.au/name/apni/116920\n\n\nAbelmoschus manihot subsp. tetraphyllus\nMalvaceae\n(Roxb. ex Hornem.) Borss.Waalk.\nAPC\naccepted\nhttps://id.biodiversity.org.au/name/apni/55945\n\n\nAbelmoschus moschatus\nMalvaceae\nMedik.\nAPC\naccepted\nhttps://id.biodiversity.org.au/name/apni/55953\n\n\nAbelmoschus moschatus subsp. biakensis\nMalvaceae\n(Hochr.) Borss.Waalk.\nAPC\naccepted\nhttps://id.biodiversity.org.au/name/apni/116595\n\n\nAbelmoschus moschatus subsp. moschatus\nMalvaceae\nNA\nAPC\naccepted\nhttps://id.biodiversity.org.au/name/apni/243806\n\n\nAbelmoschus moschatus subsp. tuberosus\nMalvaceae\n(Span.) Borss.Waalk.\nAPC\naccepted\nhttps://id.biodiversity.org.au/name/apni/55961\n\n\nAbildgaardia ovata\nCyperaceae\n(Burm.f.) Kral\nAPC\naccepted\nhttps://id.biodiversity.org.au/name/apni/150737\n\n\n\n\n\n\n\n\n\n\nunit_conversions.csv\nThe file unit_conversions.csv defines the unit conversions that are used when converting contributed trait data to common units, e.g.\n\n\n\n\n\nunit_from\nunit_to\nfunction\n\n\n\n\n%\nmg/g\nx*10\n\n\n%\ng/g\nx*0.01\n\n\n%\nmg/mg\nx*0.01\n\n\n%\nmg/kg\nx*10000\n\n\n%\n{dimensionless}\nx*.01\n\n\n%\n{count}/{count}\nx*.01\n\n\n{dimensionless}\n{count}/{count}\nx*1\n\n\na\nmo\nx*12\n\n\n{count}/m2\n{count}/mm2\nx*1/1000000\n\n\ncm\nm\nx*0.01"
  },
  {
    "objectID": "file_organisation.html#data-folder",
    "href": "file_organisation.html#data-folder",
    "title": "10  File organisation",
    "section": "10.3 /data folder",
    "text": "10.3 /data folder\nThe folder data contains the raw data from individual studies included in AusTraits.\nRecords within the data folder are organised as coming from a particular study, defined by the dataset_id. Data from each study are organised into a separate folder, with two files:\n\ndata.csv: a table containing the actual trait data.\nmetadata.yml: a file that contains study metadata (source, methods, locations, and context), maps trait names and units onto standard types, and lists any substitutions applied to the data in processing.\n\nThe folder data thus contains a long list of folders, one for each study and each containing two files:\ndata\n├── Angevin_2010\n│   ├── data.csv\n│   └── metadata.yml\n├── Barlow_1981\n│   ├── data.csv\n│   └── metadata.yml\n├── Bean_1997\n│   ├── data.csv\n│   └── metadata.yml\n├── ....\n\nwhere Angevin_2010, Barlow_1981, & Bean_1997 are each a unique dataset_id in the final dataset."
  },
  {
    "objectID": "file_organisation.html#dataset_iddata.csv",
    "href": "file_organisation.html#dataset_iddata.csv",
    "title": "10  File organisation",
    "section": "10.4 dataset_id/data.csv",
    "text": "10.4 dataset_id/data.csv\nThe file data.csv contains raw measurements and can be in either long or wide format.\nRequired columns include the taxon name, the trait name (column in long format, header in wide format), units (column in long format, part of header in wide format), location (if applicable), context (if applicable), date (if available), and trait values.\nIt is important that all trait measurements made on the same individual or that are the mean of a species’ measurements from the same location are kept linked.\n\nIf the data is in wide format, each row should include measurements made on a single individual at a single point in time or a single species-by-location mean, with different trait values as consecutive columns.\nIf the data is in long format, an additional column, individual_id, is required to ensure multiple trait measurements made on the same individual, or the mean of a species’ measurements from the same location, are linked. If the data is in wide format and there are multiple rows of data for the same individual, an individual_id column should be included. These individual_id columns ensure that related data values remain linked.\n\nWe aim to keep the data file in the rawest form possible (i.e. with as few changes as possible) but it must be a single csv file. Additional custom R code may be required to make the file exactly compatible with the AusTraits format, but these changes should be executed as AusTraits is compiled and should be in the metadata.yml file under dataset/custom_R_code (see below). Any files used to create the submitted data.csv file (e.g. Excel …) should be archived in a sub-folder within the study folder named raw."
  },
  {
    "objectID": "file_organisation.html#dataset_idmetadata.yml",
    "href": "file_organisation.html#dataset_idmetadata.yml",
    "title": "10  File organisation",
    "section": "10.5 dataset_id/metadata.yml",
    "text": "10.5 dataset_id/metadata.yml\nThe metadata is compiled in a .yml file, a structured data file where information is presented in a hierarchical format (see Appendix for details). There are 10 values at the top hierarchical level: source, contributors, dataset, locations, contexts, traits, substitutions, taxonomic_updates, exclude_observations, questions. These are each described below.\nAs a start, you may want to check out some examples from existing studies in Austraits, e.g. Angevin_2010 or Wright_2009.\n\nsource\nThis section provides citation details for the original source(s) for the data, whether it is a published journal article, book, website, or thesis. In general we aim to reference the primary source. References are written in structured yml format, under the category source and then under sub-groupings primary, secondary, and original. A reference is designated as secondary if it is a second publication by the data collector that analyses the data. When the primary reference is a compilation of multiple sources for a meta-analysis, the original references are designated as original.\nGeneral guidelines for describing a source include:\n\nA maximum of one primary source allowed.\nElements are names as in bibtex format.\nKeys should be named in the format Surname_year and the primary source is almost always identical to the name given to the dataset folder. A second instance of the identical Surname_year should have the key Surname_year_2.\nOne or more secondary source may be included if traits from a single dataset were presented in two different manuscripts. Multiple sources are also appropriate if an author has compiled data from a number of sources, which are not individually in AusTraits, for a published or unpublished compilation.\nIf your data is from an unpublished study, only include the elements that are applicable.\nIf someone has transcribed a published source, the primary source will be the published work and the person who has completed the transcription will be acknowledged as the contributor of the dataset.\n\nAn example of a primary source that is a journal article is:\nsource:\n  primary:\n    key: Falster_2005_1\n    bibtype: Article\n    author: Daniel S. Falster, Mark Westoby\n    year: 2005\n    title: Alternative height strategies among 45 dicot rain forest species from tropical Queensland, Australia\n    journal: Journal of Ecology\n    volume: 93\n    pages: 521--535\n    publisher: Wiley-Blackwell\n    doi: 10.1111/j.0022-0477.2005.00992.x\nIf a secondary source is included it may look like:\n  primary:\n    key: Choat_2006\n    bibtype: Article\n    year: '2006'\n    author: B. Choat and M. C. Ball and J. G. Luly and C. F. Donnelly and J. A. M.\n      Holtum\n    journal: Tree Physiology\n    title: Seasonal patterns of leaf gas exchange and water relations in dry rain\n      forest trees of contrasting leaf phenology\n    volume: '26'\n    number: '5'\n    pages: 657--664\n    doi: 10.1093/treephys/26.5.657\n  secondary:\n    key: Choat_2005\n    bibtype: Article\n    year: '2005'\n    author: Brendan Choat and Marilyn C. Ball and Jon G. Luly and Joseph A. M. Holtum\n    journal: Trees\n    title: Hydraulic architecture of deciduous and evergreen dry rainforest tree species\n      from north-eastern Australia\n    volume: '19'\n    number: '3'\n    pages: 305--311\n    doi: 10.1007/s00468-004-0392-1\n\n\ncontributors\nThis section provides a list of contributors to the study, their respective affiliations, roles in the study, and orcids. The following information is recorded for each data contributor:\n\n\n\n\n\n\nkey\nvalue\n\n\n\n\nlast_name\nLast name of data collector.\n\n\ngiven_name\nGiven name of data collector.\n\n\naffiliation\nAffiliation of data collector.\n\n\nORCID\nORCID ID (Open Researcher and Contributor ID) for the data collector, if available.\n\n\nnotes\noptional notes for the data collector.\n\n\nadditional_role\nAny additional roles the data collector had in the study, a field most frequently used to identify which data contributor is the contact person for the dataset.\n\n\n\n\n\n\n\n\nAn example is as follows:\n data_collectors:\n  - last_name: Falster\n    given_name: Daniel\n    ORCID: 0000-0002-9814-092X\n    affiliation: Evolution & Ecology Research Centre, School of Biological, Earth,\n      and Environmental Sciences, UNSW Sydney, Australia\n    additional_role: contact\n  - last_name: Westoby\n    given_name: Mark\n    ORCID: 0000-0001-7690-4530\n    affiliation: Department of Biological Sciences, Macquarie University, Australia\nNote that only the AusTraits custodians have the contributors’ e-mail addresses on file. This information will not be directly available to AusTraits users or new contributors via Github.\nAdditional fields within contributors are:\n\nAssistants, names of additional people who played a more minor role in data collection for the study.\ndataset_curators, names of austraits team member(s) who contacted the data collectors and added the study to the austraits repository.\n\n\n\ndataset\nThis section includes study details, including format of the data, custom r code applied to data, and various descriptors. the value entered for each element can be either a header for a column within the data.csv file or the actual value to be used.\nThe following elements are included under the element dataset:\n\ndata_is_long_format: Indicates if the data spreadsheet has a vertical (long) or horizontal (wide) configuration with yes or no terminology.\ncustom_R_code: A field where additional R code can be included. This allows for custom manipulation of the data in the submitted spreadsheet into a different format for easy integration with AusTraits. .na indicates no custom R code was used.\ncollection_date: Date sample was taken, in the format yyyy-mm-dd, yyyy-mm or yyyy, depending on the resoluton specified. Alternatively an overall range for the study can be indicating, with the starting and ending sample date sepatated by a /, as in 2010-10/2011-03\ntaxon_name: Scientific name of the taxon on which traits were sampled, without authorship. When possible, this is the currently accepted (botanical) or valid (zoological) scientific name, but might also be a higher taxonomic level.\nlocation_name: location name\nsource_id: For datasets that are compilations, an identifier for the original data source.\nindividual_id: A unique integer identifier for an individual, with individuals numbered sequentially within each dataset by taxon by population grouping. Most often each row of data represents an individual, but in some datasets trait data collected on a single individual is presented across multiple rows of data, such as if the same trait is measured using different methods or the same individual is measured repeatedly across time.\nrepeat_measurements_id: A unique integer identifier for repeat measurements of a trait that comprise a single observation, such as a response curve.\ntrait_name: Element required for long datasets to specify the column indicating the trait name associated with each row of data.\nvalue: The measured value of a trait.\ndescription: A 1-2 sentence description of the purpose of the study.\nbasis_of_record: A categorical variable specifying from which kind of specimen traits were recorded.\nlife_stage: A field to indicate the life stage or age class of the entity measured. Standard values are adult, sapling, seedling and juvenile.\nsampling_strategy: A written description of how study locations were selected and how study individuals were selected. When available, this information is lifted verbatim from a published manuscript. For preserved specimens, this field ideally indicates which records were ‘sampled’ to measure a specific trait.\nmeasurement_remarks: Brief comments or notes accompanying the trait measurement.\noriginal_file: The name of the file initially submitted to AusTraits.\nnotes: Generic notes about the study and processing of data.\n\nOf these, the fields collection_date, life_stage, basis_of_record, and measurement_remarks can all be specified at the dataset level or the traits level (which overrides a dataset-level entry) or location level (which also overrides a dataset-level entry). In each case, they can be a fixed text value or indicate a column within the data.csv file (or generated through custom_R_code) that includes the relevant information.\n\nlife_stage, basis_of_record, and collection_date are usually included under metadata$dataset unless they vary by trait.\nentity_type, replicates, basis_of_value, and value_type are usually different across traits and are usually mapped under the metadata$traits section (see below), but are allowed to be specified for the entire dataset in this section.\ntraits and value are only specified in metadata$dataset for long-format datasets.\nmeasurement_remarks and individual_id are only included if required. They are absent from the majority of datasets.\n\nAn example is as follows:\n  data_is_long_format: no\n  custom_R_code: '\n    data %&gt;%\n      mutate(\n        location_name = \"Howard River catchment\",\n        date = date %&gt;% mdy()\n      ) %&gt;%\n      arrange(date) %&gt;%\n      group_by(Tree) %&gt;%\n        mutate(observation_number = dplyr::row_number()) %&gt;%\n      ungroup() %&gt;%\n      group_by(species) %&gt;%\n        mutate(across(c(\"specific leaf area (m2 kg-1)\"), replace_duplicates_with_NA)) %&gt;%\n      ungroup()\n  '\n  collection_date: date\n  taxon_name: species\n  context_name: context\n  location_name: location_name\n  individual_id: Tree\n  description: Measurements of stem CO2 efflux and leaf gas exchange in a tropical\n    savanna ecosystem in northern Australia, and assessed the impact of fire on these\n    processes.\n  basis_of_record: field\n  life_stage: adult\n  sampling_strategy: The stem CO2 efflux was initially measured at two locations,\n    each of which was nested within a 3 km 2 plot...\n  original_file: leaf_summary.xls, Rbranch summary2.xls, and Rstem summary6.xls submitted\n    by Lucas Cernusak and archived in the raw data folder and GoogleDrive folder.\n  notes: none\nA common use of the custom_R_code is to automate the conversion of a verbal description of flowering or fruiting periods into the supported trait values. It might also be used if values for a single trait are expressed across multiple columns and need to be merged. See Catford_2014 as an example of this. The adding data vignette provides additional examples of code regularly implemented in custom_R_code, including functions specifically that were developed for AusTraits data manipulations and are in the file scripts\\custom.R.\n\n\nlocations\nThis section provides a list of study locations (sites) and information about each of the study locations where data were collected. Each should include at least three variables - latitude (deg), longitude (deg) and description. Additional variables can be included where available. Set to .na for botanical collections and field studies where data values are a mean across many locations.\nAlthough the properties listed under each location are not part of a controlled vocabulary, it is best practice to align with in-use properties whenever possible. These can be identified by running austraits$locations %&gt;% distinct(location_property).\nAn example of how a location and its properties, and the value of each property are listed (modified from Vesk_2019), is:\n  Round Hill-Nombinnie Nature Reserve:\n    latitude (deg): -32.965\n    longitude (deg): 146.161\n    precipitation, MAP (mm): 370\n    temperature, summer mean (C): 32.5\n    temperature, winter mean (C): 14.2\n    soil type: loamy red sands light red clays and light red browns earths\n    description: predominantly open Callitris glaucophylla - Eucalyptus populnea woodland\n      and Eucalyptus dumosa - E. socialis shrub mallee woodland\n    fire frequency (years): 5-20 years\n\n\ncontexts\nThis section provides contextual characteristics associated with information in traits.\nWithin the context section is a list of contextual properties, each encapsulating information read in through a different column or created through custom_R_code or as elements within specific traits (see below).\n\ncontext_property: The context property represented by the data in the column specified by var_in.\ncategory: The category of contextual data. Options are plot (a distinct collection of organisms within a single geographic location, such as plants growing on different aspects or blocks in an experiment), treatment (an experimental treatment), entity_context (contextual information to record about the entity the isn’t documented elsewhere, including the entity’s sex, caste), temporal (indicating when repeat observations are made on the same individual (or population, or taxon) across time) and method (indicating the same trait was measured on the same individual (or population, or taxon) using multiple methods).\nvar_in: Name of column with contextual data in the original data submitted.\nfind: The contextual values in the original data submitted (optional)\nvalue: The standardised contextual values, aligning syntax and wording with other studies.\ndescription: A description of the contextual values.\n\nIf the contextual values read in are appropriate and no substitutions are required, the field find can be omitted, with the values from the data.csv column entered under the field value. The field description can likewise be omitted if it is redundant; for instance, if the values are simply sequential observation numbers, times of day, or taxon names (e.g. insect host plants).\nAs with location, the context properties are not part of a controlled vocabulary, but it is best practice to align syntax with in-use properties whenever possible. These can be identified by running austraits$contexts %&gt;% distinct(context_property).\nAn example of how the contexts for a study are formatted (modified from Crous_2013), is:\ncontexts:\n- context_property: sampling season\n  category: temporal_context\n  var_in: month\n  values:\n  - find: AUG\n    value: August\n    description: August (late winter)\n  - find: DEC\n    value: December\n    description: December (early summer)\n  - find: FEB\n    value: February\n    description: February (late summer)\n- context_property: temperature treatment\n  category: treatment_context\n  var_in: Temp-trt\n  values:\n  - value: ambient\n    description: Plants grown at ambient temperatures; Jan average max = 29.4 dec\n      C / July average min = 3.2 dec C.\n  - value: elevated\n    description: Plants grown 3 deg C above ambient temperatures.\n- context_property: CO2 treatment\n  category: treatment_context\n  var_in: CO2_Treat\n  values:\n  - find: ambient CO2\n    value: 400 ppm\n    description: Plants grown at ambient CO2 (400 ppm).\n  - find: added CO2\n    value: 640 ppm\n    description: Plants grown at elevated CO2 (640 ppm); 240 ppm above ambient.\n- context_property: measurement temperature\n  category: method_context\n  var_in: method_context\n  values:\n  - find: Measurement made at 20°C\n    value: 20°C\n    description: Measurement made at 20°C\n  - find: Measurement made at 25°C\n    value: 25°C\n    description: Measurement made at 25°C\n\n\ntraits\nThis section provides a translation table, mapping traits and units from a contributed study onto corresponding variables in AusTraits. The methods used to collect the data are also specified here.\nFor each trait submitted to AusTraits, there is the following information:\n\nvar_in: Name of trait in the original data submitted.\nunit_in: Units of trait in the original data submitted.\ntrait_name: Name of the trait sampled. Allowable values specified in the table definitions.\nentity_type: A categorical variable specifying the entity corresponding to the trait values recorded.\nvalue_type: A categorical variable describing the statistical nature of the trait value recorded.\nbasis_of_record: A categorical variable specifying from which kind of specimen traits were recorded.\nbasis_of_value: A categorical variable describing how the trait value was obtained.\nreplicates: Number of replicate measurements that comprise a recorded trait measurement. A numeric value (or range) is ideal and appropriate if the value type is a mean, median, min or max. For these value types, if replication is unknown the entry should be unknown. If the value type is raw_value the replicate value should be 1. If the trait is categorical or the value indicates a measurement for an entire species (or other taxon) replicate value should be .na.\ncollection_date: Date sample was taken, in the format yyyy-mm-dd, yyyy-mm or yyyy, depending on the resoluton specified. Alternatively an overall range for the study can be indicating, with the starting and ending sample date sepatated by a /, as in 2010-10/2011-03\nmeasurement_remarks: Brief comments or notes accompanying the trait measurement.\nmethods: A textual description of the methods used to collect the trait data. Whenever available, methods are taken near-verbatim from the referenced source. Methods can include descriptions such as ‘measured on botanical collections’, ‘data from the literature’, or a detailed description of the field or lab methods used to collect the data.\nlife_stage: A field to indicate the life stage or age class of the entity measured. Standard values are adult, sapling, seedling and juvenile.\nrepeat_measurements_id: A unique integer identifier for repeat measurements of a trait that comprise a single observation, such as a response curve.\n\nThe elements trait_name, entity_type, value_type, basis_of_record, and basis of value are controlled vocabularies; the values for these elements must be from the list of allowable values. Those for traits are listed in the traits.yml file or vignette. For the other elements, see the database structure vignette.\nThe fields replicates, basis_of_value, value_type, life_stage, basis_of_record, and measurement_remarks can all be specified at the dataset level or the traits level (which overrides a dataset-level entry). In each case, they can be a fixed text value or indicate a column (within the data.csv file or generated through custom_R_code) that includes the relevant information. In addition, fields can be added to specify a specific context (most commonly a method context, but occasionally a temporal context). If such a field is added, the same name must appear in both the contexts section and for some (or all) of the traits.\nTwo examples are as follows:\n- var_in: LeafP.m\n  unit_in: mg/g\n  trait_name: leaf_P_per_dry_mass\n  entity_type: individual                   # fixed value\n  value_type: value_type_column             # referencing a column\n  basis_of_value: measurement               # fixed value\n  replicates: count                         # referencing a column\n  methods: Oven-dried leaf material was used for determination of total leaf nitrogen\n    and phosphorus. Dried ground leaf material was hot-digested in acid-peroxide before\n    colorimetric analysis using a flow injection system (QuikChem 8500, Lachat Instruments,\n    Loveland, Colorado, USA).\n\nand\n- var_in: Jmax25\n  unit_in: umol/m2/s\n  trait_name: Jmax_per_area\n  entity_type: individual                    # fixed value\n  value_type: raw                            # fixed value\n  basis_of_value: measurement                # fixed value\n  replicates: 1                              # fixed value\n  method_context: 25C                        # optional field\n  methods: Controlled photosynthetic CO2 response curve measurements were made using\n    Li-Cor 6400 portable infrared gas analysers (LiCor Inc., Lincoln, NE, USA). CO2\n    response curves of net CO2 assimilation (Anet) were developed at a constant temperature\n    (termed 'Anet-Ci curves') for intact leaves within each tree chamber. These Anet-Ci\n    curve measurements progressed at four to five specified leaf temperatures for\n    the same leaf (i.e. one leaf per chamber) in each of three seasons (early summer,\n    December 2010; late summer, February 2011...\n\n\n\nsubstitutions\nThis section provides a list of any “find and replace” substitutions needed to get the data into the right format.\nSubstitutions are required whenever the exact word(s) used to describe a categorical trait value in AusTraits is different from the vocabulary used by the author in the data.csv file. It is preferable to align vocabulary using substitutions rather than changing the data.csv file. The trait definitions file provides a list of supported values for each trait.\nEach substitution is documented using the following elements:\n\ntrait_name: Trait where substitutions are required.\nfind: Contributor’s trait value that needs to be changed.\nreplace: AusTraits supported replacement value.\n\nAn example is as follows:\nsubstitutions:\n- trait_name: life_history\n  find: p\n  replace: perennial\n- trait_name: plant_growth_form\n  find: s\n  replace: shrub\n- ...\n\n\ntaxonomic_updates\nThis section provides a table of taxonomic name changes needed to align original names in the dataset with taxon names in the chosen taxonomic reference(s).\nEach substitution is documented using the following elements:\n\nfind: Name given to taxon in the original data supplied by the authors.\nreplace: Scientific name of the taxon on which traits were sampled, without authorship. When possible, this is the currently accepted (botanical) or valid (zoological) scientific name, but might also be a higher taxonomic level.\nreason: Records why the change was implemented, e.g. typos, taxonomic synonyms, and standardising spellings\n\nAlgorithms within AusTraits automatically align outdated taxonomy and taxonomic synonyms to their currently accepted scientific name, so such adjustments are not documented as substitutions.\nSome examples of taxonomic updates are as follows:\ntaxonomic_updates:\n- find: Drummondita rubroviridis\n  replace: Drummondita rubriviridis\n  reason: match_07_fuzzy. Fuzzy alignment with accepted canonical name in APC (2022-11-21)\n  taxonomic_resolution: Species\n- find: Acacia ancistrophylla/sclerophylla\n  replace: Acacia sp. [Acacia ancistrophylla/sclerophylla; White_2020]\n  reason: match_04. Rewording taxon where `/` indicates uncertain species identification\n    to align with `APC accepted` genus (2022-11-10)\n  taxonomic_resolution: genus\n- find: Polyalthia (Wyvur)\n  replace: Polyalthia sp. (Wyvuri B.P.Hyland RFK2632)\n  reason: match_15_fuzzy. Fuzzy match alignment with species-level canonical name\n    in `APC known` when everything except first 2 words ignored (2022-11-10)\n  taxonomic_resolution: Species\n\n\nquestions\nThis section provides a place to record any queries we have about the dataset (recorded as a named array), including notes on any additional traits that may have been collected in the study but have not been incorporated into austraits.\nAn example is as follows:\nquestions:\n  questions for author: Triglochin procera has very different seed masses in the main traits spreadsheet and the field seeds worksheet. Which is correct? There are a number of species with values in the field leaves worksheet that are absent in the main traits worksheet - we have included this data into Austraits; please advise if this was inappropriate.\n  austraits: need to map aquatic_terrestrial onto an actual trait once one is created."
  },
  {
    "objectID": "file_organisation.html#rcustom_r_code.r",
    "href": "file_organisation.html#rcustom_r_code.r",
    "title": "10  File organisation",
    "section": "10.6 R/custom_R_code.R",
    "text": "10.6 R/custom_R_code.R\nXXX\nThe austraits.build compilation contains an extra folder, R containning a file custom_R_code.R. This file documents any custom functions used in the compilation, called as part of the custom_R_code section of metadata files."
  },
  {
    "objectID": "create_dictionary.html",
    "href": "create_dictionary.html",
    "title": "11  Creating a dictionary",
    "section": "",
    "text": "XXX a"
  },
  {
    "objectID": "adding_data.html",
    "href": "adding_data.html",
    "title": "12  Adding datasets",
    "section": "",
    "text": "13 Getting started\nThe traits.build repository includes a selection of functions that help build the repository. To use these, you’ll need to make them available.\nThe easiest way to load the functions into your workspace is to run the following (from within the repository)\nBefore starting the quality checks, it is helpful to assign a variable, current_study:\nThis lets you have a list of tests you run for each study and you just have to reassign a new dataset_id to current_study.\nIt is best to run tests and fix formatting first.\nBy far our preferred way of contributing is for you to contribute files directly into the repository and then send a pull request with your input. You can do this by\nIn short,\nBefore you make a substantial pull request, you should always file an issue and make sure someone from the team agrees that it’s worth pursuing the problem. If you’ve found a bug, create an associated issue and illustrate the bug with a minimal reprex illustrating the issue.\nIf this is not possible, you could email the relevant files (see above) to the AusTraits email: austraits.database@gmail.com"
  },
  {
    "objectID": "adding_data.html#an-overview-of-the-main-steps",
    "href": "adding_data.html#an-overview-of-the-main-steps",
    "title": "12  Adding datasets",
    "section": "12.1 An overview of the main steps",
    "text": "12.1 An overview of the main steps\n\nClone the traits.build repository from github\nCreate a new branch in the repo, named for the new dataset_id in author_year format, e.g. Gallagher_2014.\nCreate a new folder within the folder data with the name dataset_id, e.g. Gallagher_2014.\nPrepare the file data.csv and place it within the new folder (details here).\nPrepare the file metadata.yml and place it within the new folder (details here).\nAdd the new study into the build framework and rebuild AusTraits, by running build_setup_pipeline().\n\nThis step updates the file remake.yml with appropriate rules for the new dataset; similarly if you remove datasets, do the same. (At this stage, remake offers no looping constructs, so for now we generate the remake file using: whisker.)\nYou can then rebuild AusTraits, including your dataset.\n\nRun tests and quality checks on the newly added dataset and correct the data.csv and metadata.yml files as necessary (details here).\nGenerate and proofread a report on the data. In particular, check that numeric trait values fall within a logical range relative to other studies, and that individual trait observations are not unnecessarily excluded because their trait values are unsupported.\nReturn to step 6 if changes are made to the data.csv or metadata.yml files.\nPush the GitHub branch.\n\nIt may help to download one of the existing datasets to use as a template for your own files and a guide on required content. You should look at the files in the config folder, particularly the definitions file for the list of traits we cover and the supported trait values for each trait. The GitHub repository also hosts a compiled trait definitions table.\nThe remainder of this vignette provides incredibly detailed instructions for steps 4-8 above. It is intended for anyone wishing to add datasets to either AusTraits itself or to use the traits.build workflow to create a separate database."
  },
  {
    "objectID": "adding_data.html#add-a-new-folder",
    "href": "adding_data.html#add-a-new-folder",
    "title": "12  Adding datasets",
    "section": "14.1 Add a new folder",
    "text": "14.1 Add a new folder\nAdd a new folder within the data folder. Its name should be the study’s dataset_id, the core organising unit behind AusTraits.\nThe preferred format for dataset_id is the surname of the first author of any corresponding publication, followed by the year, as surname_year. E.g. Falster_2005. Wherever there are multiple studies with the same id, we add a suffix _2, _3 etc. E.g.Falster_2005, Falster_2005_2."
  },
  {
    "objectID": "adding_data.html#csv_file",
    "href": "adding_data.html#csv_file",
    "title": "12  Adding datasets",
    "section": "14.2 Constructing the data.csv file",
    "text": "14.2 Constructing the data.csv file\nAll data for a study (dataset_id) must be merged into a single spreadsheet: data.csv. All accompanying metadata is read in through the metadata.yml file. Some information must be input explicitly through the data.csv or metdata.yml file, while other information can be entered via either file; this is explicitly indicated for each element.\n\nRequired columns: Columns within the data.csv file must include taxon name, location_name (if there are multiple locations), contexts (if appropriate), and collection_date (if appropriate). The data.csv file can either be in a wide format (1 column for each trait, with trait name as the column header) or long format (a single column for all trait values and additional columns for trait name and units)\n\n\nFor all field studies, ensure there is a column for location_name. If all measurements were made at a single location, a location_name column can easily be mutated using custom_R_code within the metadata.yml file. See sections adding locations and adding contexts below for more information on compiling location and context data.\nIf available, be sure to include a column with collection date. If possible, provide in yyyy-mm-dd (e.g. 2020-03-05) format or, if the day of the month isn’t known, as yyyy-mm (e.g. 2020-03). However, any format is allowed and the column can be parsed to the proper yyyy-mm-dd format using custom_R_code. If the same collection date applies to the entire study it can be added directly into the metadata.yml file.\nIf applicable, ensure there are columns for an context properties, including experimental treatments, specific differences in method, a stratified sampling scheme within a plot, or sampling season. Additional context columns could be added through custom_R_code or keyed in where traits are added, but it is best to include a column in the data.csv file whenever possible. The protocol for adding context properties to the metadata file is under adding contexts\n\n\nSummarising data: Data submitted by a contributor should be in the rawest form possible; always request data with individual measurements over location/species means. Some studies make replicate measurements on an individual at a single point in time. For these studies, individual means need to be calculated, as AusTraits does not include multiple measurements per individual. The raw values are preserved in the contributor’s raw data files. Be sure to calculate the number of replicates that contributed to each mean value.\n\nWhen there is just a single row of values to summarise, use:\nread_csv(\"data/dataset_id/raw/raw_data.csv\") %&gt;%\n  mutate(leaf_area_replicates = 1) %&gt;%\n  group_by(individual, `species name`, location, context, etc) %&gt;%\n  summarise(\n    leaf_area_mean = mean(leaf_area),\n    leaf_area_replicates = sum(leaf_area_replicates)\n    ) %&gt;%\n  ungroup()\n(Make sure you group_by all categorical variables you want to retain, for only columns that are grouping variables will be kept)\nWhen you want to take the mean of a series of continuous variables, use:\nread_csv(\"data/dataset_id/raw/raw_data.csv\") %&gt;%\n  mutate(replicates = 1) %&gt;%\n  group_by(individual, `species name`, location, context, etc) %&gt;%\n  summarise(\n    across(\n      c(leaf_area, `leaf N`), .fns = mean,\n      c(replicates), .fns = sum,\n      c(growth_form, `photosynthetic pathway`), .fns = first\n    )\n  ) %&gt;%\n  ungroup()\n\nCategorical variables not included as grouping variables will return NA\nThis allows you to retain character variables, but can be tedious with many columns. Generally use the function first for categorical variables - it simply retains the trait value in the first column. In the rare case when rows in a particular grouping have different categorical values, more complex manipulations are required.\nYou can identify runs of columns by column number/position. For instance c(5:25), .fns = mean or c(leaf_area:leaf_N), .fns = mean\n\n\nMerging multiple spreadsheets: If multiple spreadsheets of data are submitted these must be merged together.\n\n\nIf the spreadsheets include different trait measurements made on the same individual (or location means for the same species), they are best merged using full_join, specifying all conditions that need to be matched across spreadsheets (e.g. individual, species, location, context). Ensure the column names are identical between spreadsheets or specify columns that need to be matched.\n\nread_csv(\"data/dataset_id/raw/data_file_1.csv\") -&gt; data_1\nread_csv(\"data/dataset_id/raw/data_file_2.csv\") -&gt; data_2\ndata_1 %&gt;% full_join(data_2, by = c(\"Individual\", \"Taxon\", \"Location\", \"Context\"))\n\nIf the spreadsheets include trait measurements for different individuals (or possibly data at different scales - such as individual level data for some traits and species means for other traits), they are best merged using bind_rows. Ensure the column names for taxon name, location name, context, individual, and collection date are identical between spreadsheets. If there are data for the same traits in both spreadsheets, make sure those column headers are identical as well.\n\nread_csv(\"data/dataset_id/raw/data_file_1.csv\") -&gt; data_1\nread_csv(\"data/dataset_id/raw/data_file_2.csv\") -&gt; data_2\ndata_1 %&gt;% bind_rows(data_2)\n\nTaxon names: Taxon names need to be complete names. If the main data file includes code names, with a key as a separate file, they need to be merged:\n\nread_csv(\"data/dataset_id/raw/species_key.csv\") -&gt; species_key\nread_csv(\"data/dataset_id/raw/data_file.csv\") %&gt;%\n  left_join(species_key, by = \"code\")\n\nUnexpected hangups\n\nWhen Excel saves an .xls file as a .csv file it only preserves the number of significant figures that are displayed on the screen. This means that if, for some reason, a column has been set to display a very low number of significant figures or a column is very narrow, data quality is lost.\nIf you’re reading a file into R where there are lots of blanks at the beginning of a column of numeric data, the defaults for read_csv fail to register the column as numeric. It is fixed by adding the argument guess_max:\n\nread_csv(\"data/dataset_id/raw/raw_data.csv\", guess_max = 10000)\nThis checks 10,000 rows of data before declaring the column is non-numeric. The value can be set even higher…"
  },
  {
    "objectID": "adding_data.html#metadata_file",
    "href": "adding_data.html#metadata_file",
    "title": "12  Adding datasets",
    "section": "14.3 Constructing the metadata.yml file",
    "text": "14.3 Constructing the metadata.yml file\nOne way to construct the metadata.yml file is to use one of the existing files and modify yours to follow the same format. As a start, check out some examples from existing studies in AusTraits, e.g. Angevin_2011 or Wright_2009.\nNote, when editing the metadata.yml, edits should be made in a proper text editor (Microsoft word tends to mess up the formatting). For example, Rstudio, textmate, sublime text, and Visual Studio Code are all good editors.\nTo assist you in constructing the metadata.yml file, we have developed functions to help fill in the different sections of the file. You can then manually edit the file further to fill in missing details.\nFirst run the following to make the functions available\nlibrary(traits.build)\nThe functions for populating the metadata file all begin with metadata_. A list of the available functions is automatically generated within the man/ folder within the traits.build directory.\n\nCreating a template\nCreate a basic template for the metadata.yml file for your study. Note, it requires you to have already created a file data.csv in the folder data/your_dataset_id.\nLet’s imagine you’re entering a study called Yang_2028\ncurrent_study &lt;- \"Yang_2028\"\n\nmetadata_create_template(current_study)\n\n# or simply\n\nmetadata_create_template(\"Yang_2028\")\nThe function will ask a series of questions and then create a relatively empty file data/your_dataset_id/metadata.yml. The key questions are:\n\nIs the data long vs wide? A wide dataset has each variable (i.e. trait ) as a column. A long dataset has a single row containing all trait values and additional columns specifying units and trait_name.\nSelect column for taxon_name\nSelect column for trait_name (long datasets only)\nSelect column for trait values (long datasets only)\nSelect column for location_name\nSelect column for individual_id (a column that links measurements on the same individual)\nSelect column for collection_date\n\nIf your data.csv file does not yet have a location_name column, this information can later be added manually.\n\n\nAdding a source\nThree functions are available to help with entering citation details for the source data.\nThe function metadata_create_template creates a template for the primary source with default fields for a journal article, which you can then edit manually.\nIf you have a doi for your study, use the function:\nmetadata_add_source_doi(dataset_id = current_study, doi = \"doi\")\nand the different elements within the source will automatically be generated. Double check the information added to ensure: 1. The title is in sentence case 2. Overall, the information isn’t in all caps (information from a few journals is read in like this) 3. Pages numbers are present and added as, for example, 123 -- 134 ; note the -- between page numbers\nBy default, details are added as the primary source. If multiple sources are linked to a single dataset_id, you can specify a source as secondary. Attempting to add a second primary source will overwrite the information already input.\nmetadata_add_source_doi(dataset_id, doi, type = \"secondary\")\n\nSecondary sources will be assigned the same dataset_id as the primary source. Manually edit the key in the metadata.yml file to be the appropriate author_yyyy code for the secondary reference. Sequential qualifiers can be used if necessary (e.g. author_yyyy_2)\nA “secondary” source might be either a second research output from the main dataset (truly a secondary source) or the original source of some data compiled for a metaanalysis (an original source). After adding a second source, you must manually change the source’s header to beginning with either secondary or original, as is appropriate.\nIf there are many sources to add (i.e. for datasets compiled for metaanalyses), after you add each reference, go to the metadata.yml file and manually change the source’s header from original to original_01 (and then original_02, etc.; or secondary_01 ; secondary_02). See Richards_2008 for an example of a complex source list.\n\nAlternatively, if you have reference details saved in a bibtex file called myref.bib you can use the function\nmetadata_add_source_doi(dataset_id, file = \"myref.bib\")\n(These options require the packages rcrossref and RefManageR to be installed.)\nFor a book, the proper format is:\nsource:\n  primary:\n      key: Cooper_2013\n      bibtype: Book\n      year: 2013\n      author: Wendy Cooper and William T. Cooper\n      title: Australian rainforest fruits\n      publisher: CSIRO Publishing\n      pages: 272\nFor an online resource, the proper format is:\nsource:\n  primary:\n    key: TMAG_2009\n    bibtype: Online\n    author: '{Tasmanian Herbarium}'\n    year: 2009\n    title: Flora of Tasmania Online\n    publisher: Tasmanian Museum & Art Gallery (Hobart)\n    url: http://www.tmag.tas.gov.au/floratasmania\nFor a thesis, the proper format is:\nsource:\n  primary:\n      key: Kanowski_2000\n      bibtype: Thesis\n      year: 1999\n      author: John Kanowski\n      title: Ecological determinants of the distribution and abundance of the folivorous\n        marsupials endemic to the rainforests of the Atherton uplands, north Queensland.\n      type: PhD\n      institution: James Cook University, Townsville\nFor an unpublished dataset, the proper format is:\nsource:\n  primary:\n    key: Ooi_2018\n    bibtype: Unpublished\n    year: 2018\n    author: Mark K. J. Ooi\n    title: \"Unpublished data: Herbivory survey within Royal National Park, University\n      of New South Wales\"\nIf you manually add information, note that if there is a colon (:) or apostrophe (’) in a reference, the text for that line must be in quotes (“).\n\n\nAdding contributors\nThe skeletal metadata.yml file created by the function metadata_create_template includes a template for entering details about data contributors. Edit this manually, duplicating if details for multiple people are required.\n\nAuthorship is extended to anyone who played a key intellectual role in the experimental design and data collection. Most studies have 1-3 authors. For each author, please provide a last_name, given_name, institutional affiliation, email address, and their ORCID (if available). Nominate a single contributor to be the dataset’s point of contact; this person’s email will not be listed in the metadata file, but is the person future AusTraits users are likely to seek out if they have questions.\nAdditional field assistants can be listed under assistants:\nThe AusTraits data entry person is listed under dataset_curators:\n\nFor example, in Roderick_2002\ncontributors:\n  data_collectors:\n  - last_name: Roderick\n    given_name: Michael\n    ORCID: 0000-0002-3630-7739\n    affiliation: The Australian National University, Australia\n    additional_role: contact\n  assistants: Michelle Cochrane\n  dataset_curators: Elizabeth Wenk\n\n\nCustom R code\nFor many studies there are changes we want to make to a dataset before the data.csv file is read into AusTraits. These most often include applying a function to transform data, a function to filter data, or a function to replace a contributor’s “measurement missing” placeholder symbol with NA. In each case it is appropriate to leave the rawer data in data.csv.\n\nBackground\nIn each case we want to make some custom modifications to a particular dataset before the common pipeline of operations gets applied. To make this possible, the workflow allows for some custom R code to be run as a first step in the processing pipeline. That pipeline (the function process_custom_code called within dataset_process) looks like this:\ndata &lt;-\n  read_csv(filename_data_raw, col_types = cols(), guess_max = 1e5) %&gt;%\n  process_custom_code(metadata[[\"dataset\"]][[\"custom_R_code\"]])() %&gt;%\n  process_parse_data(dataset_id, metadata, contexts, schema)\nNote the second line. This is where the custom code gets applied, right after the file is loaded.\n\n\nSummary\n\nsource the file containing functions the AusTraits team have explicitly developed to use within the custom_R_code field: source(\"R/custom_R_code.R\")\nassume a single object called data, and apply whatever fixes are needed\n\nuse functions from the packages dplyr or tiydr, like mutate, rename, etc, and otherwise avoid external packages\n\nalternatively, use the functions we’ve created explicitly for pre-processing data that were sourced through the file custom.R. In consultation with AusTraits team leaders you can add functions to this file.\nbe fully self-contained (we’re not going to use any of the other remake machinery here)\nuse pipes to weave together a single statement, where possible. (Otherwise you’ll need a semi colons ; at the end of each statement).\nplace a single apostrophe (’) at the start and end of your custom R code; this allows you to add line breaks between pipes.\n\n\n\nExamples of appropriate use of custom R code\n\nMost sources from herbaria record flowering_time and fruiting_time as a span of months, while AusTraits codes these variables as a sequence of 12 N’s and Y’s for the 12 months. A series of functions make this conversion in custom_R_code. These include:\n\n‘format_flowering_months’ (Create flowering times from start to end pair)\n‘convert_month_range_string_to_binary’ (Converts flowering and fruiting month ranges to 12 element character strings of binary data)\n‘convert_month_range_vec_to_binary’ (Convert vectors of month range to 12 element character strings of binary data)\n‘collapse_multirow_phenology_data_to_binary_vec’ (Converts multirow phenology data to a 12 digit binary string)\n\nMany datasets from herbaria record traits like leaf_length, leaf_width, seed_length, etc. as a range (e.g. 2-8). The function separate_range separates this data into a pair of columns with minimum and maximum values, required to properly align units\nDuplicate values within a study need to be filtered out.\n\nIf a species-level measurement has been entered for all within-location replicates, you need to filter out the duplicates. This is true for both numeric and categorical values.\ndata %&gt;%\n  group_by(Species) %&gt;%\n    mutate(\n      across(c(`leaf_percentN`, `plant growth form`), replace_duplicates_with_NA)\n      ) %&gt;%\n  ungroup()\nNote: You would use group_by(Species, Location) if there are unique values at the species x location level.\n\nValues that were sourced from a different study need to be filtered out. See Duplicates between studies below - functions to automate this process are in progress.\nAuthor has represented missing data values with a symbol, such as 0 :\n\ndata %&gt;% mutate(across(c(`height (cm)`, `leaf area (mm2)`), ~ na_if(., 0)))\n\nIf a subset of data in a column are also values for a second trait in AusTraits, some data values can be duplicated in a second temporary column. In the example below, some data in the contributor’s fruit_type column also apply to the trait fruit_fleshiness in AusTraits:\n\ndata %&gt;% mutate(fruit_fleshiness = ifelse(`fruit type` == \"pome\", \"fleshy\", NA))\n\nIf a subset of data in a column are instead values for a second trait in AusTraits, some data values can be moved to a second column (second trait), using the function ‘move_values_to_new_trait’. In the example below, some data in the contributor’s growth_form column only apply to the trait parasitic in AusTraits. Note you need to create a blank variable to move the trait values to.\n\ndata %&gt;%\n  mutate(new_trait = NA_character) %&gt;%\n  move_values_to_new_trait(\n    original_trait= \"growth form\",\n    new_trait = \"parasitic\",\n    original_values = \"parasitic\",\n    values_for_new_trait = \"parasitic\",\n    values_to_keep = \"NA\")\nor\ndata %&gt;%\n  mutate(dispersal_appendage = NA.char) %&gt;%\n  move_values_to_new_trait(\n    \"fruits\", \"dispersal_appendage\",\n    c(\"dry & winged\", \"enclosed in aril\"),\n    c(\"wings\", \"aril\"),\n    c(\"NA\", \"enclosed\")\n  )\n\nNote, the parameter values_to_keep currently doesn’t accept NA ; this bug is known and will be fixed.\n\n\nIf the data.csv file includes raw data that you want to manipulate into a trait, or the contributor presents the data in a different formulation than AusTraits:\n\ndata %&gt;% mutate(root_mass_fraction = `root mass` / (`root mass` + `shoot mass`))\n\nYou can do manipulations, such as adding a column with locations or manipulating location names. This is only recommended for studies with a single (or few) location, where manually adding the location data to the metadata.yml file is fast, since in precludes automatically propagating location data into metadata (see Adding location details). As an example, see Blackman_2010:\n\ndata %&gt;%\n  mutate(\n    location_name = ifelse(location_name == \"Mt Field\" & habitat == \"Montane rainforest\", \"Mt Field_wet\", location_name),\n    location_name = ifelse(location_name == \"Mt Field\" & habitat == \"Dry sclerophyll\", \"Mt Field_dry\", location_name)\n  )\n\nYou can generate observation_numbers for sequential measurements on the same individual\n\ndata %&gt;%\n  group_by(Tree) %&gt;%\n    mutate(observation_number = row_number()) %&gt;%\n  ungroup()\n\nYou can generatemeasurement_remarks from more cryptic notes\n\ndata %&gt;%\n  mutate(\n        measurement_remarks = ifelse(material == \"FRESH\",\"fresh leaves (indicating amount of leaf moisture)\", NA),\n        measurement_remarks = ifelse(material == \"DRIED\",\"dry leaves (indicating amount of leaf moisture)\", measurement_remarks),\n        measurement_remarks = ifelse(material == \"SENESCED\",\"senesced leaves (indicating amount of leaf moisture)\", measurement_remarks),\n  )\n\nYou can reformat collection_dates supplied into the yyyy-mm-dd format, or add a date column\n\nConverting from any mdy format to yyyy-mm-dd (e.g. Dec 3 2015 to 2015-12-03)\ndata %&gt;% mutate(Date = Date %&gt;% mdy())\nConverting from any dmy format to yyyy-mm-dd (e.g. 3-12-2015 to 2015-12-03)\ndata %&gt;% mutate(Date = Date %&gt;% dmy())\nConverting from a mmm-yyyy (string) format to yyyy-mm (e.g. Dec 2015 to 2015-12)\ndata %&gt;% mutate(Date = parse_date_time(Date, orders = \"my\") %&gt;% format.Date(\"%Y-%m\"))\nConverting from a mdy format to yyyy-mm (e.g. Excel has reinterpreted the data as full dates 12-01-2015 but the resolution should be “month” 2015-12)\ndata %&gt;% mutate(Date = parse_date_time(Date, orders = \"mdy\") %&gt;% format.Date(\"%Y-%m\"))\nA particularly complicated example where some dates are presented as yyyy-mm and others as yyyy-mm-dd\ndata %&gt;%\n    mutate(\n      weird_date = ifelse(str_detect(gathering_date, \"^[0-9]{4}\"), gathering_date, NA),\n      gathering_date = gathering_date %&gt;% mdy(quiet = T) %&gt;% as.character(),\n      gathering_date = coalesce(gathering_date, weird_date)\n    ) %&gt;%\n    select(-weird_date)\n\n\nTesting your custom R code\nAfter you’ve added the custom R code to a file, check that it has completed the intended data frame manipulation:\nmetadata_check_custom_R_code(\"Blackman_2010\")\nYou could alternatively read the data.csv file into R and run the code line by line.\n\n\n\nFill in metadata$dataset\nThe dataset section is a mix of fields that are filled in automatically during metadata_create_template() and fields that need to be manually filled in.\n\nindividual_id Individual_id is one of the fields that can be read in during metadata_create_template. However, you may instead mutate your own individual_id using custom_R_code and add it in manually. For a wide dataset individual_id is required anytime there are multiple rows of data for the same individual and you want to keep these linked. This field should only be included if it is required.\n\nWARNING If you have an entry individual_id: unknown this assigns all rows of data to an individual named “unknown” and the entire dataset will be assumed to be from a single individual. This is why it is essential to omit this field if there isn’t an actual row of data being read in.\n\ncollection_date If this is not read in as a specified column, it needs to be filled in manually as start date/end date in yyyy-mm-dd, yyyy-mm, or yyyy format, depending on the relevant resolution. If the collection dates are unknown, write unknown/publication year\ndescription: 1-2 sentence description of the study’s goals. The abstract of a manuscript usually includes some good sentences/phrases to borrow.\nbasis_of_record: Allowable values include: field, field_experiment, captive_cultivated, lab, preserved_specimen, and literature. See the top of system.file(\"support\", \"traits.build_schema.yml\", package = \"traits.build\" or database structure vignette for definitions of these accepted basis_of_record values. This field can also be read in from a column or can be specified at the location or trait level, as described below. Entries under metadata$locations or metadata$traits (which apply to only that specific location or trait) override the global value entered under metadata$dataset.\nlife_stage: Allowable values include: adult, sapling, seedling, juvenile. This field can also be read in from a column or can be specified at the location or trait level, as described below. Entries under metadata$locations or metadata$traits (which apply to only that specific location or trait) override the global value entered under metadata$dataset.\nsampling_strategy: Often a quite long description of the sampling strategy, extracted verbatim from a manuscript.\noriginal_file: The name of the file initially submitted to AusTraits and archived in a Google Drive folder and usually in the dataset folder, in a subfolder named raw.\nnotes: Notes about the study and processing of data, especially if there were complications or if some data is suspected duplicates with another study and were filtered out.\n\nThere are also fields that will only be used for a subset of datasets:\n\nmeasurement_remarks: Measurement remarks is a field to capture a miscellaneous notes column. This should be information that is not captured by “methods” (which is fixed to a single value for a trait). It can be read in for the whole dataset, or entered under dataset$traits if the remarks only apply to specific traits.\nentity_type, value_type, replicates, and basis_of_value are standardly added to each trait, but a fixed value or column could be read in under metadata$dataset\n\n\n\nAdd traits\nBegin by automatically adding all traits to your skeletal metadata.yml file:\nmetadata_add_traits(current_study)\nYou will be asked to indicate the columns you wish to keep as distinct traits. Include all columns with trait data.\nThis automatically propagates each trait selected into metadata.yml as follows where var_in is the name of a column in the data.csv file (for wide datasets) or a unique trait name values in the trait_name column (for a long dataset):\n- var_in: leaf area (mm2)\n  unit_in: .na\n  trait_name: .na\n  entity_type: .na\n  value_type: .na\n  basis_of_value: .na\n  replicates: .na\n  methods: .na\nThe trait details then need to be filled in manually.\n\nunits: fill in the units specified by the author - such as mm2. If you’re uncertain about the syntax/format used for some more complex units, look through the traits definition file (config/traits.yml) or the file showing unit conversions (config/unit_conversions.csv). For categorical variables, leave this as .na.\ntrait_name: This is the appropriate trait name from config/traits.yml. If no appropriate trait exists in AusTraits, a new trait can often be added - just ensure it is a trait where data will be comparable across studies and has been measured for a fair number (~&gt;50) species. For currently unsupported traits, we leave this as .na but then fill in the rest of the data and flag this study as having a potential new trait. Then in the future, when this trait is added to the traits.yml file, the data can be read into AusTraits by simply replacing the .na with a trait name.\nentity_type: Entity types indicate the taxonomic/ecological hierarchical level corresponding to the trait value. Entity types can be individual, population, species, genus, family or order. Metapopulation-level measurements are coded as population and infraspecific taxon-level measurements are coded as species. See the top of system.file(\"support\", \"traits.build_schema.yml\", package = \"traits.build\") for definitions of these accepted entity types. Note: entity_type is about the hierarchical level to which the trait measurement refers; this is separate from the taxonomic resolution of the entity’s name.\nvalue_type: Allowable value types are mean, minimum, maximum, mode, range, raw, and bin. See the top of system.file(\"support\", \"traits.build_schema.yml\", package = \"traits.build\") for definitions of these accepted value types. All categorical traits are generally scored as being a mode, the most commonly observed value. Note that for values that are bins, the two numbers are separated by a double-hyphen, 1 -- 10.\nbasis_of_value: Basis of value indicates how a value was determined. Allowable terms are measurement, expert_score, model_derived, and literature. See the top of system.file(\"support\", \"traits.build_schema.yml\", package = \"traits.build\") for definitions of these accepted value types, but in general most categorical traits are values that have been scored by an expert (expert_score) and more numeric trait values are measurements.\nreplicates: Fill in with the appropriate value. For categorical variables, leave this as .na. If there is a column that specifies replicate number, you can list the column name in the field.\nmethods: This information can usually be copied verbatim from a manuscript. In general, methods sections extracted from pdfs include “special characters” (non-UTF-8 characters). Non-English alphabet characters are recognised (e.g. é, ö) and should remain unchanged. Other characters will be re-formatted during the study input process, so double check that degree symbols (º), en-dashes (–), em-dashes (—), and curly quotes (‘,’,“,”) have been maintained or reformatted with a suitable alternative. Greek letters and some other characters are replaced with their Unicode equivalent (e.g. &lt;U+03A8&gt; replaces Psi (Ψ)); for these it is best to replace the symbol with an interpretable English-character equivalent.\n\nNote with methods, if the identical methods apply to a string of traits, for the first trait use the following syntax, where the &leaf_length_method notation assigns the remaining text in the field as the leaf_length_method.\n\n  methods: &leaf_length_method All measurements were from dry herbarium collections, with leaf and bracteole measurements taken from the largest of these structures on each specimen.\nThen for the next trait that uses this method you can just include. At the end of processing you can read/write the yml file and this will fill in the assigned text throughout.\n  methods: *leaf_length_method\n\nIn addition to the automatically propagated fields, there are a number of optional fields you can add if appropriate.\n\nlife_stage If all measurements in a dataset were made on plants of the same life stage a global value should be entered under metadata$dataset. However if different traits were measured at different life stages or different rows of data represent measurements at different life stages you can specify a unique life stage for each trait or indicate a column where this information is stored.\nbasis_of_record If all measurements in a dataset represent the same basis_of_record a global value should be entered under metadata$dataset. However if different traits have different basis_of_record values or different rows of data represent different basis_of_record values you can specify a unique basis_of_record value for each trait or indicate a column where this information is stored.\nmeasurement_remarks: Measurement remarks is a field to indicate miscellaneous comments. If these comments only apply to specific trait(s), this field should be specified with those trait’s metadata sections. This meant to be information that is not captured by “methods” (which is fixed to a single value for a trait).\nmethod_context If different columns in a wide data.csv file indicate measurements on the same trait using different methods, this needs to be designated. At the bottom of the trait’s metadata, add a method_context_name field (e.g. method_context words well). Write a word or short phrase that indicates which method context applies to that trait (data column). For instance, one trait might have method_context: fully expanded leaves and a second entry with the same trait name and method might have method_context: leaves still expanding. The method context details must also be added to the contexts section.\ntemporal_context If different columns in a wide data.csv file indicate measurements on the same trait, on the same individuals at different points in time, this needs to be designated. At the bottom of the trait’s metadata, add a temporal_context_name field (e.g. temporal_context words well). Write a word or short phrase that indicates which temporal context applies to that trait (data column). For instance, one trait might have temporal_context: dry season and a second entry with the same trait name and method might have temporal_context: after rain. The temporal context details must also be added to the contexts section.\n\n\n\nAdding location details\nLocation data includes location names, latitude/longitude coordinates, verbal location descriptions, and any additional abiotic/biotic location variables provided by the contributor (or in the accompanying manuscript). For studies with more than a few locations, it is most efficient to create a table of this data that is automatically read into the metadata.yml file.\n\nLocation names must be identical (including syntax, case) to those in data.csv\nColumn headers for latitude and longitude data must read latitude (deg) and longitude (deg)\nLatitude and longitude must be in decimal degrees (i.e. -46.5832). There are many online converters to convert from degrees,minutes,seconds format or UTM. Or use the following formula: decimal_degrees = degrees + (minutes/60) + (seconds/3600)\nIf there is a column with a general vegetation description (i.e. rainforest, coastal heath it should be titled description)\nAlthough location properties are not restricted to a controlled vocabulary, newly added studies should use the same location property syntax as others whenever possible, to allow future discoverability. To generate a list of already used under location_property, use:\n\naustraits$locations %&gt;% distinct(location_property)\nA few contributors provide a standalone file of all location data. Otherwise, the following sequence works well:\n\nIdentify all location names in the data.csv file. The following code extracts a list of location names and any other columns in the data file that include location-specific information:\n\nread_csv(\"data/dataset_id/data.csv\") %&gt;%\n  distinct(location, .keep_all = TRUE) %&gt;% # the argument `.keep_all` ensures columns aren't dropped\n  select(location, rainfall, lat, lon) %&gt;% # list of relevant columns to keep\n  rename(all_of(c(\"latitude (deg)\" = \"lat\", \"longitude (deg)\" = \"long\")))  # rename columns to how you want them to appear in the metadata file. Faster to do it once here than repeatedly in the metadata file\n  write_csv(\"data/dataset_id/raw/location_data.csv\")\n\nOpen the spreadsheet in Excel (or any editor of your choice) and manually add any additional data from the manuscript. Save as a .csv file.\nOpen in R\n\nread_csv(\"data/dataset_id/raw/location_data.csv\") -&gt; location_data\nAs an example of what the location table should look like:\n\nThis location data can then be read into metadata.yml:\n\nmetadata_add_locations(current_study, site_data)\nYou are first prompted to identify the column with the location name and then to list all columns that contain location data. This automatically fills in the location component on the metadata file.\nIt is possible that you will want to specify life_stage or basis_of_record at the location_level. You can later manually add these fields to some or all locations.\n(During processing location_id’s are automatically generated and paired with each location_name.)\n\n\nContext details\nThe dictionary definition of a context is the situation within which something exists or happens, and that can help explain it. This is exactly what context_properties are in AusTraits, ancillary information that is important to explaining and understanding a trait value.\nAusTraits recognises 5 categories of contexts: - treatment contexts are experimental treatments applied to individuals, such as soil nutrient manipulations, growing temperatures, or CO2 enchancement. - plot contexts are either blocks/plots within an experimental design or a variable that has been measured within a location and measurements have been stratified across this variable. Topographic position within a location is an example of this. - temporal contexts relate to repeat measurements on the same entity (individual, population, or species) across time. They may simply be number observations or might be explicitly linked to growing season or time of day. - method contexts indicate that the same trait has been measured on the same entity (individual, population or species) using multiple methods. These might be samples from different canopy light environments, different leaf ages, or sapwood samples from different branch diameters. - entity_contexts capture ancillary information about the entity (individual, population or species) that helps explain the measured trait values. This might be the entity’s sex, caste (for social insects), or host plant (for insects).\nContext properties are not restricted to a controlled vocabulary. However, newly added studies should use the same context property syntax as others whenever possible, to allow future discoverability. To generate a list of terms already used under context_property, use:\naustraits$contexts %&gt;% distinct(context_property)\nThe AusTraits workflow can handle as many context properties as is required. These are most easily read with the dedicated function\nmetadata_add_contexts(dataset_id)\nThe function first displays a list of all data columns (from the data.csv file) and prompts you to select those that are context properties. For each column you are asked to indicate its category (those described above). You are shown a list of unique values present in the data column and asked if these require any substitutions. This function adds the following information to the section metadata$contexts (example from Crous_2013)\n- context_property: unknown\n  category: temporal_context\n  var_in: month\n  values:\n  - find: AUG\n    value: unknown\n    description: unknown\n  - find: DEC\n    value: unknown\n    description: unknown\n  - find: FEB\n    value: unknown\n    description: unknown\n- context_property: unknown\n  category: treatment_context\n  var_in: Temp-trt\n  values:\n  - value: ambient\n    description: unknown\n  - value: elevated\n    description: unknown\n- context_property: unknown\n  category: treatment_context\n  var_in: CO2_Treat\n  values:\n  - find: ambient CO2\n    value: unknown\n    description: unknown\n  - find: added CO2\n    value: unknown\n    description: unknown\nYou must then manually fill in the fields designated as unknown. You are permitted to omit the description field if the context_property value itself provides sufficient description.\nIf there are additional context properties that were designated in the traits section, these will have to be added manually, as this information is not captured in a column. A final output might be:\n- context_property: sampling season\n  category: temporal_context\n  var_in: month\n  values:\n  - find: AUG\n    value: August\n    description: August (late winter)\n  - find: DEC\n    value: December\n    description: December (early summer)\n  - find: FEB\n    value: February\n    description: February (late summer)\n- context_property: temperature treatment\n  category: treatment_context\n  var_in: Temp-trt\n  values:\n  - value: ambient\n    description: Plants grown at ambient temperatures; Jan average max = 29.4 dec\n      C / July average min = 3.2 dec C.\n  - value: elevated\n    description: Plants grown 3 deg C above ambient temperatures.\n- context_property: CO2 treatment\n  category: treatment_context\n  var_in: CO2_Treat\n  values:\n  - find: ambient CO2\n    value: 400 ppm\n    description: Plants grown at ambient CO2 (400 ppm).\n  - find: added CO2\n    value: 640 ppm\n    description: Plants grown at elevated CO2 (640 ppm); 240 ppm above ambient.\n- context_property: measurement temperature\n  category: method_context\n  var_in: method_context          #this field would be included in the relevant traits\n  values:\n  - value: 20°C                   # this value would be keyed in through the relevant traits\n    description: Measurement made at 20°C\n  - value: 25°C\n    description: Measurement made at 25°C\n\n\nUsing substitutions\nIt is very unlikely that a contributor will use categorical trait values that are entirely identical to those in the traits.yml file. You need to add substitutions for those that do not exactly align to match the wording and syntax supported by AusTraits. Combinations of multiple trait values are allowed - simply list them, space delimited (e.g. shrub tree for a species whose growth form includes both)\nSingle substitutions can be added by running:\nmetadata_add_substitution(current_study, \"trait_name\", \"find\", \"replace\")\nwhere trait_name is the AusTraits defined trait name, find is the trait value used in the data.csv file and replace is the trait value supported by AusTraits.\nIf you have many substitutions to add, the following may be more efficient:\n\nAdd a single substitution via the function and then copy and paste the lines many times in the metadata.yml file, changing the relevant fields\nCreate a spreadsheet with a list of all trait_name by trait_value combinations requiring substitutions. The spreadsheet would have four columns with headers dataset_id, trait_name, find and replace. This table can be read directly into the metadata.yml file using the function metadata_add_substitutions_table. This is described below under Adding many substitutions.\n\n\nExcluded data\nThis section of the metadata.yml file provides the capacity to explicitly exclude specific trait values or taxon names. These are values that are in the data.csv file but should be excluded from AusTraits.\nIt includes three elements: - variable: A variable from the traits table, typically taxon_name, location_name or context_name - find: Value of variable to remove - reason: Records why the data was removed, e.g. exotic\nMultiple, comma-delimited values can be added under find.\nFor example, in Munroe_2019:\nexclude_observations:\n- variable: taxon_name\n  find: Campylopus introflexus, Dicranoloma menziesii, Philonotis tenuis, Polytrichastrum\n    alpinum, Polytrichum juniperinum, Sphagnum cristatum\n  reason: moss (E Wenk, 2020.06.18)\n- variable: taxon_name\n  find: Xanthoparmelia semiviridis\n  reason: lichen (E Wenk, 2020.06.18)\n\n\nQuestions\nThe final section of the metadata.yml file is titled questions. This is a location to:\n\nAsk the data contributor targeted questions about their study. When you generate a report (described below) these questions will appear at the top of the report.\n\nPreface the first question you have with contributor: (indented once), and additional questions with question2:, etc.\nAsk contributors about missing metadata\nPoint contributors attention to odd data distributions, to make sure they look at those traits extra carefully.\nLet contributors know if you’re uncertain about their units or if you transformed the data in a fairly major way.\nAsk the contributors if you’re uncertain you aligned their trait names correctly.\n\nThis is a place to list any trait data that are not yet traits supported by AusTraits. Use the following syntax, indented once: additional_traits:, followed by a list of traits.\n\n\n\nHooray! You now have a fully propagated metadata.yml file!\nNext is making sure it has captured all the data exactly as you’ve intended."
  },
  {
    "objectID": "adding_data.html#clear-formatting",
    "href": "adding_data.html#clear-formatting",
    "title": "12  Adding datasets",
    "section": "15.1 Clear formatting",
    "text": "15.1 Clear formatting\nThe clear formatting code below reads and re-writes the yaml file. This is the same process that is repeated when running functions that automatically add substitutions or check taxonomy. Running it first ensures that any formatting issues introduced (or fixed) during the read/write process are identified and solved first.\nFor instance, the write_metadata function inserts line breaks every 80 characters and reworks other line breaks (except in custom_R_code). It also reformats special characters in the text, substituting in its accepted format for degree symbols, en-dashes, em-dashes and quotes, and substituting in Unicode codes for more obscure symbols.\nf &lt;- file.path(\"data\", current_study, \"metadata.yml\")\nread_metadata(f) %&gt;% write_metadata(f)"
  },
  {
    "objectID": "adding_data.html#running_tests",
    "href": "adding_data.html#running_tests",
    "title": "12  Adding datasets",
    "section": "15.2 Running tests",
    "text": "15.2 Running tests\nBegin by running some automated tests to ensure the dataset meets the required set up. The tests run through a collection of pre-specified checks on the files for each study. The output alerts you to possible issues needing to be fixed, by comparing the data in the files with the expected structure and allowed values, as specified in the schema and definitions.\nCertain special characters may show up as errors and need to be manually adjusted in the metadata.yml file\nThe tests also identify mismatches between the location names in the data.csv file vs. metadata.yml file (same for context), unsupported trait names, etc.\nTo run the tests, the variable dataset_ids must be defined in the global namespace, containing a vector of ids to check. For example:\n# load relevant functions\nlibrary(traits.build)\n\n# Tests run test on one study\ndataset_ids &lt;- \"Bragg_2002\"\ndataset_test(dataset_ids)\n\n# Tests run test on all studies\ndataset_ids &lt;- dir(\"data\")\ndataset_test(dataset_ids)\nFix as many errors as you can and then rerun dataset_test() repeatedly until no errors remain.\nSee below for suggestions on how to implement large numbers of trait value substitutions."
  },
  {
    "objectID": "adding_data.html#rebuild-austraits",
    "href": "adding_data.html#rebuild-austraits",
    "title": "12  Adding datasets",
    "section": "15.3 Rebuild AusTraits",
    "text": "15.3 Rebuild AusTraits\nNow incorporate the new study into AusTraits:\nbuild_setup_pipeline()\naustraits &lt;- remake::make(\"austraits\")"
  },
  {
    "objectID": "adding_data.html#check-excluded-data",
    "href": "adding_data.html#check-excluded-data",
    "title": "12  Adding datasets",
    "section": "15.4 Check excluded data",
    "text": "15.4 Check excluded data\nAusTraits automatically excludes data for a number of reasons. These are available in the frame excluded_data.\nWhen you are finished running quality checks, no data should be excluded due to Missing unit conversion and Unsupported trait.\nA few values may be legitimately excluded due to other errors, but check each entry.\nThe best way to view excluded data for a study is:\naustraits$excluded_data %&gt;%\n  filter(\n    dataset_id == current_study,\n    error != \"Observation excluded in metadata\"\n  ) %&gt;%\n  View()\nMissing values (blank cells, cells with NA) are not included in the excluded_data table, because they are assumed to be legitimate blanks. If you want to confirm this, you need to temporarily change the default arguments for the internal function dataset_process where it is called within the remake.yml file. For instance, the default,\n      dataset_process(\"data/Ahrens_2019/data.csv\",\n                  Ahrens_2019_config,\n                  schema\n                 )\nneeds to be changed to:\n      dataset_process(\"data/Ahrens_2019/data.csv\",\n                  Ahrens_2019_config,\n                  schema,\n                  filter_missing_values = FALSE\n                 )\n\nReasons for data to be excluded\nPossible reasons for excluding a trait value includes:\n\nMissing species name: Species name is missing from data.csv file for a given row of data. This usually occurs when there are stray characters in the data.csv file below the data – delete these rows.\nMissing unit conversion: Value was present but appropriate unit conversion was missing. This requires that you add a new unit conversion to the file config/unit_conversions.csv. Add additional conversions near similar unit conversions already in the file for easier searching in the future.\nObservation excluded in metadata: Specific values, usually certain taxon names can be excluded in the metadata. This is generally used when a study includes a number of non-native and non-naturalised species that need to be excluded. These should be intentional exclusions, as they have been added by you.\nTime contains non-number: Indicates a problem with the value entered into the traits flowering_time and fruiting_time. (Note to AusTraits custodians: This error should no longer appear - will retain for now as a placeholder.)\nUnsupported trait: trait_name not listed in config/traits.yml, under traits. Double check you have used the correct spelling/exact syntax for the trait_name, adding a new trait to the traits.yml file if appropriate. If there is a trait that is currently unsupported by AusTraits, leave trait_name: .na. Do not fill in an arbitrary name.\nUnsupported trait value: This error, referencing categorical traits, means that the value for a trait is not included in the list of supported trait values for that trait in config/traits.yml. See adding many substitutions if there are many trait values requiring substitutions. If appropriate, add another trait value to the traits.yml file, but confer with other curators, as the lists of trait values have been carefully agreed upon through workshop sessions.\nValue does not convert to numeric: Is there a strange character in the file preventing easy conversion? This error is rare and generally justified.\nValue out of allowable range: This error, referencing numeric traits, means that the trait value, after unit conversions, falls outside of the allowable range specified for that trait in config/traits.yml. Sometimes the AusTraits range is too narrow and other times the author’s value is truly an outlier that should be excluded. Look closely at these and adjust the range in config/traits.yml if justified. Generally, don’t change the range until you’ve create a report for the study and confirmed that the general cloud of data aligns with other studies as excepted. Most frequently the units or unit conversion is what is incorrect.\n\nYou can also ask how many of each error type are present for a study:\n\naustraits$excluded_data %&gt;%\n  filter(dataset_id == \"Cheal_2017\") %&gt;%\n  pull(error) %&gt;%\n  table()\n#&gt; &lt; table of extent 0 &gt;\n\nOr produce a table of error type by trait:\n\naustraits$excluded_data %&gt;%\n  filter(\n    dataset_id == \"Cheal_2017\",\n  ) %&gt;%\n  select(trait_name, error) %&gt;%\n  table()\n#&gt; &lt; table of extent 0 x 0 &gt;\n\nNote, most studies have no excluded data. This study is an extreme example!"
  },
  {
    "objectID": "adding_data.html#adding_many_substitutions",
    "href": "adding_data.html#adding_many_substitutions",
    "title": "12  Adding datasets",
    "section": "15.5 Adding many substitutions",
    "text": "15.5 Adding many substitutions\nFor categorical traits, if you want to create a list of all values that require substitutions:\naustraits$excluded_data %&gt;%\n  filter(\n    dataset_id == current_study,\n    error == \"Unsupported trait value\"\n  ) %&gt;%\n  distinct(dataset_id, trait_name, value) %&gt;%\n  rename(\"find\" = \"value\") %&gt;%\n  select(-dataset_id) %&gt;%\n  write_csv(\"data/dataset_id/raw/substitutions_required.csv\")\nFor studies with a small number of substitutions, add them individually using:\nmetadata_add_substitution(dataset_id, trait_name, find, replace)\nFor studies with large number of substitutions required, you can add an additional column to this table, replace, and fill in all the correct trait values. Then read the list of substitutions directly into the metadata file:\nsubstitutions_to_add &lt;-\n  read_csv(\"data/dataset_id/raw/substitutions_required_after_editing.csv\")\n\nmetadata_add_substitutions_list(dataset_id, substitutions_to_add)"
  },
  {
    "objectID": "adding_data.html#add-taxonomic-updates",
    "href": "adding_data.html#add-taxonomic-updates",
    "title": "12  Adding datasets",
    "section": "15.6 Add taxonomic updates",
    "text": "15.6 Add taxonomic updates\nThe function add_taxonomic_updates allows you to manually align submitted taxon names (the original_name) with the taxon names in the taxonomic resource.\n  metadata_add_taxonomic_change &lt;- function(dataset_id, find, replace, reason, taxonomic_resolution)\n\nfind is the name in the taxon name column in the dataset\nreplace is the equivalent taxon name in the taxonomic resource\nreason provides information about why the taxonomic update is required\ntaxonomic_resolution indicates the most specific taxon rank that the name in replace aligns to\n\nAs examples:\nA simple fix correcting a minor typo to align with an accepted taxon name:\ntaxonomic_updates:\n- find: Drummondita rubroviridis\n  replace: Drummondita rubriviridis\n  reason: match_07_fuzzy. Fuzzy alignment with accepted canonical name in APC (2022-11-21)\n  taxonomic_resolution: Species\nAn example of a taxon name that can only be aligned to genus. The taxonomic_resolution is therefore specified as genus. The portion of the name that can be aligned to the taxonomic resource must be before the square brackets. Any information within the square brackets is important for uniquely identifying this entry within AusTraits, but does not provide additional taxonomic information.\n- find: Acacia ancistrophylla/sclerophylla\n  replace: Acacia sp. [Acacia ancistrophylla/sclerophylla; White_2020]\n  reason: match_04. Rewording taxon where `/` indicates uncertain species identification\n    to align with `APC accepted` genus (2022-11-10)\n  taxonomic_resolution: genus\nA taxonomic update that aligns a name to the most similar taxon_name within a taxonomic resource (the APC), but this is a taxonomic synonym and the austraits workflow will update it to its currently accepted name (since this is documented within the taxon_list.csv file):\n- find: Polyalthia (Wyvur)\n  replace: Polyalthia sp. (Wyvuri B.P.Hyland RFK2632)\n  reason: match_15_fuzzy. Fuzzy match alignment with species-level canonical name\n    in `APC known` when everything except first 2 words ignored (2022-11-10)\n  taxonomic_resolution: Species"
  },
  {
    "objectID": "adding_data.html#check-if-austraits-pivots-wider",
    "href": "adding_data.html#check-if-austraits-pivots-wider",
    "title": "12  Adding datasets",
    "section": "15.7 Check if AusTraits pivots wider",
    "text": "15.7 Check if AusTraits pivots wider\nAusTraits users want to be able to “pivot” between long and wide formats. Each row of data should have a unique combination of the following fields: trait_name, dataset_id, observation_id, source_id, taxon_name, population_id, individual_id, temporal_context_id, method_id, value_type, and original_name\nTherefore, the dataset should be able to pivot wider and the following code should have a 1 in every cell.\naustraits$traits %&gt;%\n  select(dataset_id, trait_name, value, observation_id, source_id, taxon_name, population_id, individual_id, temporal_context_id, method_id, value_type, original_name) %&gt;%\n  pivot_wider(names_from = trait_name, values_from = value, values_fn = length) %&gt;% View()\nIf AusTraits fails to pivot_wider, likely problems are: - Not all context information has been captured. For instance, is it possible that you have two columns with data for the same trait, measured using different methods? In this case you need to add a method_context to both the relevant traits and to the contexts section. - There are multiple observations per entity. In a number of large studies which, in theory, include a single observation per species, have a few scattered instances of a second row of trait values with the same taxon name. They might be true duplicates and can be removed or perhaps they are indeed some alternate values. In this case the following custom_R_code works:\n' data %&gt;%\n    group_by(taxon_name) %&gt;%\n      mutate(observation_number = dplyr::row_number()) %&gt;%\n    ungroup()'\nThen add observation_number as a context with category: temporal_context"
  },
  {
    "objectID": "adding_data.html#check-for-duplicates",
    "href": "adding_data.html#check-for-duplicates",
    "title": "12  Adding datasets",
    "section": "15.8 Check for duplicates",
    "text": "15.8 Check for duplicates\nAusTraits strives to have no duplicate entries for numeric (continuous) trait measurements. That is, each value in AusTraits should represent a unique measurement, rather than a measurement sourced from another study.\nWhen you receive/solicit a dataset, ask the data contributor if all data submitted was collected for the specific study and if they suspect other studies from their lab/colleagues may also have contributed any of this data.\nIn addition, there are tests to check for duplicates within and across dataset_ids.\nTo check for duplicates:\naustraits_deduped &lt;- remove_suspected_duplicates(austraits)\nduplicates_for_dataset_id &lt;-\n  austraits_deduped$excluded_data %&gt;%\n  filter(\n    dataset_id == current_study\n  )\n\nDuplicates within the study\n\nFirst sort duplicates_for_dataset_id by the column error and scan for duplicates within the study (these will be entries under error that begin with the same dataset_id as the dataset being processed)\nFor legitimately identical measurements, do nothing. For instance, if %N has been measured on 50 replicates of a species and is reported to the nearest 0.01% it is quite likely there will be a few identical values within the study.\nIf a species-level measurement has been entered for all within-location replicates, you need to filter out the duplicates. This is true for both numeric and categorical values. Enter the following code as custom_R_code in the dataset’s metadata file:\n\ndata %&gt;%\n  group_by(Species) %&gt;%\n  mutate(\n    across(\n      c(leaf_percentN, `plant growth form`), replace_duplicates_with_NA)\n    )\n  ) %&gt;%\n  ungroup()\nNote: Using custom R code instead of filtering the values in the data.csv file itself ensures the relevant trait values are still associated with each line of data in the data.csv file, but only read into AusTraits a single time. Note: You would use group_by(Species, Location) if there are unique values at the species x location level.\n\n\nDuplicates between studies\nAusTraits does not attempt to filter out duplicates in categorical traits between studies. The commonly duplicated traits like life_form, plant_growth_form, photosynthetic_pathway, fire_response, etc. are legitimately duplicated and if the occasional study reported a different plant_growth_form or fire_response it would be important to have documented that one trait value was much more common than another. Such categorical trait values may have been sourced from reference material or measured/identified by this research team.\nIdentifying duplicates in numeric traits between studies can be difficult, but it is essential that we attempt to filter out all duplicate occurrences of the same measurement. Some common patterns of duplication include:\n\nFor a single trait, if there are a large number of values duplicated in a specific other dataset_id (i.e. the error repeatedly starts with the same dataset_id), be suspicious. Before contacting the author, check the metadata for the two datasets, especially authors and study locations, to see if it is likely these are data values that have been jointly collected and shared across studies. Similar location names/locations, identical university affiliations, or similar lists of traits being measured are good clues.\nplant_height, leaf_length, leaf_width, seed_length, seed_width and seed_mass are the numeric variables that are most frequently sourced from reference material (e.g. floras, herbarium collections, reference books, Kew seed database, etc.)\nThe following datasets are flagged in AusTraits as reference studies and are the source of most duplicates for the variables listed above: Kew_2019_1, Kew_2019_2, Kew_2019_3, Kew_2019_4, Kew_2019_5, Kew_2019_6, ANBG_2019, GrassBase_2014, CPBR_2002, NTH_2014,RBGK_2014, NHNSW_2016, RBGSYD__2014_2, RBGSYD_2014, TMAG_2009, WAH_1998, WAH_2016,Brock_1993, Barlow_1981, Hyland_2003, Cooper_2013\n\nData from these studies are assumed to be the source, and the other study with the value is assumed to have sourced it from the above study. We recognise this is not always accurate, especially for compilations within Kew_2019_1, Kew’s seed mass database. Whenever we input a raw dataset that is also part of the Kew compilation, we filter that contributors data from Kew_2019_1.\n\nData for wood_density is also often sourced from other studies, most commonly Ilic_2000 or Zanne_2009.\nData from a number of studies from Leishman and Wright have been extensively shared within the trait ecology community, especially through TRY\n\nIf the dataset you are processing has a number of numeric trait duplicates that follow one of the patterns of duplication listed, the duplicates should be filtered out. Any other data explicitly indicated in the manuscript as sourced should also be filtered out. Most difficult are studies that have partially sourced data, often from many small studies, and partially collected new data, but not identified the source of each value.\nFiltering duplicate data is a three-step process. In brief:\n\nIdentify traits and studies with duplicates you believe should be removed.\nAdd additional columns to data.csv, identifying certain trait_values as duplicates.\nAdd custom R code that filters out identified duplicates when the study is merged into AusTraits.\n\n\nIdentify traits and studies\n\nEither in R or Excel, manipulate duplicates_for_dataset_id to remove rows that you believe are legitimate duplicates, including duplicates values due to replicate measurements within a single study and stray duplicates across studies that likely true, incidental duplicate values. Carefully consider which datasets and traits to include/exclude from the filter.\n\nAs an example:\n# Note, this code will be replaced by a function in the future.\nduplicates_to_filter &lt;-\n  duplicates_for_dataset_id %&gt;%\n  mutate(\n    dataset_with_duplicate =\n      error %&gt;%\n        gsub(\"Duplicate of \", \"\", .) %&gt;%\n        gsub(\"[[:alnum:]]$\", \"\", .) %&gt;%\n        gsub(\"[[:punct:]]$\", \"\", .)\n  ) %&gt;%\n  filter(dataset_with_duplicate %in% c(\"Ilic_2000\", \"Zanne_2009\", \"Kew_2019_1\", \"Barlow_1981\", \"NTH_2014\")) %&gt;%\n  filter(trait_name %in% c(\"wood_density\", \"seed_mass\", \"leaf_length\", \"leaf_width\"))\n\nUse the following code to add columns to data.csv that identify specific values as duplicates:\n\n# Note, this code will be replaced by a function in the future.\nwood_density_duplicates &lt;-\n  duplicates_to_filter %&gt;%\n  filter(trait_name == \"wood_density\") %&gt;%\n  select(error, original_name) %&gt;%\n  rename(\"wood_density_duplicate\" = \"error\")\n\nseed_mass_duplicates &lt;-\n  duplicates_to_filter %&gt;%\n  filter(trait_name == \"seed_width\") %&gt;%\n  select(error, original_name) %&gt;%\n  rename(\"seed_mass_duplicate\" = \"error\")\n\nleaf_width_min_duplicates &lt;-\n  duplicates_to_filter %&gt;%\n  filter(trait_name == \"leaf_width\", value_type == \"expert_min\") %&gt;%\n  select(error, original_name) %&gt;%\n  rename(\"leaf_width_min_duplicate\" = \"error\")\n\nleaf_width_max_duplicates &lt;-\n  duplicates_to_filter %&gt;%\n  filter(trait_name == \"leaf_width\", value_type == \"expert_max\") %&gt;%\n  select(error, original_name) %&gt;%\n  rename(\"leaf_width_max_duplicate\" = \"error\")\n\nleaf_length_min_duplicates &lt;-\n  duplicates_to_filter %&gt;%\n  filter(trait_name == \"leaf_length\", value_type == \"expert_min\") %&gt;%\n  select(error, original_name) %&gt;%\n  rename(\"leaf_length_min_duplicate\" = \"error\")\n\nleaf_length_max_duplicates &lt;-\n  duplicates_to_filter %&gt;%\n  filter(trait_name == \"leaf_length\", value_type == \"expert_max\") %&gt;%\n  select(error, original_name) %&gt;%\n  rename(\"leaf_length_max_duplicate\" = \"error\")\n\nread_csv(\"data/dataset_id/data.csv\") %&gt;%\n  left_join(wood_density_duplicates, by = c(\"column_with_taxon_name\" = \"original_name\")) %&gt;%\n  left_join(seed_mass_duplicates, by = c(\"column_with_taxon_name\" = \"original_name\")) %&gt;%\n  left_join(leaf_width_min_duplicates, by = c(\"column_with_taxon_name\" = \"original_name\")) %&gt;%\n  left_join(leaf_width_max_duplicates, by = c(\"column_with_taxon_name\" = \"original_name\")) %&gt;%\n  left_join(leaf_length_min_duplicates, by = c(\"column_with_taxon_name\" = \"original_name\")) %&gt;%\n  left_join(leaf_length_max_duplicates, by = c(\"column_with_taxon_name\" = \"original_name\")) %&gt;%\n  write_csv(\"data/dataset_id/data.csv\")\n\nFor the above example, then add the following code to custom R code, removing the duplicate values from the data columns (by setting them as NA) as the dataset is read into AusTraits.\n\ndata %&gt;%\n  mutate(\n    `wood density` = ifelse(is.na(wood_density_duplicate), `wood density`, NA),\n    `seed mass (mg)` = ifelse(is.na(seed_mass_duplicate), `seed mass (mg)`, NA),\n    `leaf width minimum (mm)` = ifelse(is.na(leaf_width_min_duplicate), `leaf width minimum (mm)`, NA),\n    `leaf width maximum (mm)` = ifelse(is.na(leaf_width_max_duplicate), `leaf width maximum (mm)`, NA),\n    `leaf length minimum (mm)` = ifelse(is.na(leaf_length_min_duplicate), `leaf length minimum (mm)`, NA),\n    `leaf length maximum (mm)` = ifelse(is.na(leaf_length_max_duplicate), `leaf length maximum (mm)`, NA)\n  )\nDifficulties:\n\nThis method only identifies values as duplicates if they have the same number of significant figures.\nMore complex matching may reveal further duplicates. For seed mass in particular, some studies likely source values from the Kew database and then round these values. They may similarly source several values from Kew and then include the mean in their dataset. If their methods or correspondence with the contributor suggests the values were sourced from Kew (or another lab, papers, etc.) it is best to filter out all values, EXCEPT species that are not yet represented in AusTraits for the trait in question."
  },
  {
    "objectID": "adding_data.html#build-study-report",
    "href": "adding_data.html#build-study-report",
    "title": "12  Adding datasets",
    "section": "15.9 Build study report",
    "text": "15.9 Build study report\nThe report is located in the export folder.\nCheck the study report to ensure:\n\nAll possible metadata fields were filled in\nThe locations plot sensibly on the map of Australia\nFor numeric traits, the trait values plot sensibly relative to other studies\nThe list of unknown/unmatched species doesn’t include names you think should be recognised/aligned\n\nIf necessary, cycle back through earlier steps to fix any errors, rebuilding the study report as necessary\nAt the very end, re-clear formatting, re-run tests, rebuild AusTraits, rebuild report.\nIf you’re uncertain, also recheck excluded data and duplicates before these final steps.\nf &lt;- file.path(\"data\", current_study, \"metadata.yml\")\nread_metadata(f) %&gt;% write_metadata(f)\n\ndataset_ids &lt;- current_study\naustraits_run_tests()\n\naustraits &lt;- remake::make(\"austraits\")\ndataset_report(current_study, overwrite = TRUE)\nTo generate a report for a collection of studies:\ndataset_reports(c(\"Falster_2005_1\", \"Wright_2002\"), overwrite = TRUE)\nOr for all studies:\ndataset_reports(overwrite = TRUE)\nAdd the argument overwrite=TRUE if you already have a copy of a specific report stored in your computer and want to replace it with a newer version.\n(Reports are written in Rmarkdown and generated via the knitr package. The template is stored in scripts/report_study.html)."
  },
  {
    "objectID": "adding_data.html#merging-a-pull-request",
    "href": "adding_data.html#merging-a-pull-request",
    "title": "12  Adding datasets",
    "section": "16.1 Merging a pull request",
    "text": "16.1 Merging a pull request\nThere are multiple ways to merge a pull request, including using GitHub’s built-in options for merging and squashing. When merging a PR, we ideally want\n\na single commit\nto attribute the work to the original author\nto run various checks along the way\n\nThere are two ways to do this. For both, you need to be an approved maintainer.\n\nMerging in your own PR\nYou can merge in your own PR after you’ve had someone else review it.\n\nSend the PR\nTag someone to review\nOnce ready, merge into main choosing “Squash & Merge”, using an informative commit message.\n\n\n\nMerging someone else’s PR\nWhen merging in someone else’s PR, the built-in options aren’t ideal, as they either take all of the commits on a branch (ugh, messy), OR make the commit under the name of the person merging the request.\nThe workflow below describes how to merge a pull request from the command line, with a single commit & attributing the work to the original author. Lets assume a branch of name Smith_1995.\nFirst, from the master branch in the repo, run the following:\ngit merge --squash origin/Smith_1995\nThen in R\nNow back in the terminal\ngit add .\ngit commit\nAdd a commit message, referencing relevant pull requests and issues, e.g.\nSmith_1995: Import new data\n\nFor #224, closes #286\nAnd finally, amend the commit author, to reference the person who did all the work!\ngit commit --amend --author \"XXX &lt;XXX@gmail.com&gt;\""
  },
  {
    "objectID": "adding_data.html#commit-messages",
    "href": "adding_data.html#commit-messages",
    "title": "12  Adding datasets",
    "section": "16.2 Commit messages",
    "text": "16.2 Commit messages\nInformative commit messages are ideal. Where possible, these should reference the issue being addressed. They should clearly describe the work done and value added to AusTraits in a few, clear, bulleted points."
  },
  {
    "objectID": "adding_data.html#version-updating-making-a-new-release",
    "href": "adding_data.html#version-updating-making-a-new-release",
    "title": "12  Adding datasets",
    "section": "16.3 Version updating & Making a new release",
    "text": "16.3 Version updating & Making a new release\nReleases of the dataset are snapshots that are archived and available for use.\nWe use semantic versioning to label our versions. As discussed in Falster et al 2019, semantic versioning can apply to datasets as well as code.\nThe version number will have 3 components for actual releases, and 4 for development versions. The structure is major.minor.patch.dev, where dev is at least 9000. The dev component provides a visual signal that this is a development version. So, if the current version is 0.9.1.9000, the release be 0.9.2, 0.10.0 or 1.0.0.\nOur approach to incrementing version numbers is\n\nmajor: increment when you make changes to the structure that are likely incompatible with any code written to work with previous versions.\nminor: increment to communicate any changes to the structure that are likely to be compatible with any code written to work with the previous versions (i.e., allows code to run without error). Such changes might involve adding new data within the existing structure, so that the previous dataset version exists as a subset of the new version. For tabular data, this includes adding columns or rows. On the other hand, removing data should constitute a major version because records previously relied on may no longer exist.\npatch: Increment to communicate correction of errors in the actual data, without any changes to the structure. Such changes are unlikely to break or change analyses written with the previous version in a substantial way.\n\n\nFigure: Semantic versioning communicates to users the types of changes that have occurred between successive versions of an evolving dataset, using a tri-digit label where increments in a number indicate major, minor, and patch-level changes, respectively. From Falster et al 2019, (CC-BY).\nThe process of making a release is as follows. Note that corresponding releases and versions are needed in both austraits and traits.build:\n\nUpdate the version number in the DESCRIPTION file, using `\nCompile traits.build.\nUpdate the documentation.\nCommit and push to github.\nMake a release on github, adding version number\nPrepare for the next version by updating version numbers."
  },
  {
    "objectID": "adding_data.html#extracting-data-from-pdf-tables",
    "href": "adding_data.html#extracting-data-from-pdf-tables",
    "title": "12  Adding datasets",
    "section": "16.4 Extracting data from PDF tables",
    "text": "16.4 Extracting data from PDF tables\nIf you encounter a PDF table of data and need to extract values, this can be achieved with the tabula-java tool. There’s actually an R wrapper (called tabulizer), but we haven’t succeeded in getting this running. However, it’s easy enough to run the java tool at the command line on OSX.\n\nDownload latest release of tabula-java and save the file in your path\nRun\n\njava -jar tabula-1.0.3-jar-with-dependencies.jar my_table.pdf -o my_data.csv\nThis should output the data from the table in my_table.pdf into the csv my_data.csv\n\nClean up in Excel. check especially that the locations of white spaces are correct."
  },
  {
    "objectID": "custom_R_code.html",
    "href": "custom_R_code.html",
    "title": "13  Adding custom_R_code",
    "section": "",
    "text": "Occasionally all the changes we want to make to dataset may not fit into the prescribed workflow used in AusTraits. For example, we assume that each trait has a single unit. But there are a few datasets where data on different rows have different units. So we want to make to make some custom modifications to this particular dataset before the common pipeline of operations gets applied. To make this possible, the workflow allows for some custom R code to be run as a first step in the processing pipeline. That pipeline (in the function read_data_study) looks like:\n\ndata &lt;-\n  read_csv(filename_data_raw, col_types = cols()) %&gt;%\n  process_custom_code(metadata[[\"dataset\"]][[\"custom_R_code\"]])() %&gt;%\n  process_parse_data(dataset_id, metadata, contexts, schema) %&gt;%\n  ...()\n\nNote the second line.\n\nExample problem\nAs an example, for Blackman_2010 we want to combine two columns to create an appropriate location variable. Here is the code that was included in data/Blackman_2010/metadata.yml under custom_R_code.\n\ndata %&gt;% mutate(\n  location = ifelse(location == \"Mt Field\" & habitat == \"Montane rainforest\", \"Mt Field_wet\", location),\n  location = ifelse(location == \"Mt Field\" & habitat == \"Dry sclerophyll\", \"Mt Field_dry\", location)\n)\n\nThis is the finished solution, but to get there we did as follows:\nGenerally, this code should\n\nassume a single object called data, and apply whatever fixes are needed\nuse dplyr functions like mutate, rename, etc\nuse pipes to weave together a single statement, if possible. (Otherwise you’ll need a semi colon ; at the end of each statement).\nbe fully self-contained (we’re not going to use any of the other remake machinery here)\n\nFirst, load an object called data:\n\nlibrary(readr)\nlibrary(yaml)\n\ndata &lt;- read_csv(file.path(\"data\", \"Blackman_2010\", \"data.csv\"), col_types = cols())\ndata\n\nSecond, write your code to manipulate data, like the example above\nThird, once you have some working code, you then want to add it into your yml file under dataset -&gt; custom_R_code.\nFinally, check it works. Let’s assume you added it in. The function metadata_check_custom_R_code loads the data and applies the custom R code:\n\nmetadata_check_custom_R_code(\"Blackman_2010\")"
  },
  {
    "objectID": "publishing.html",
    "href": "publishing.html",
    "title": "14  Publishing",
    "section": "",
    "text": "traits.build is an R package that was first developed to build AusTraits, a harmonised, open-source database of Australian plant traits. The code has been transformed into a standalone package allowing anyone to build a relational, tabular database for any taxonomic group and any collection of traits.\nThe project’s guiding principles are to:\n\nCreate open-source, harmonised, reproducible databases from disparate datasets.\nProvide a fully transparent workflow.\nOffer a relational database structure that fully documents the contextual data essential to interpreting ecological data.\nOffer a straightforward, robust template for building a trait dictionary.\nOffer a database structure that is flexible enough to accommodate the complexities inherent to ecological data.\nOffer a database structure that is underlain by a documented ontology, ensuring each database field is interpretable and interoperable with other databases and data structures."
  },
  {
    "objectID": "using_data.html#output-formats",
    "href": "using_data.html#output-formats",
    "title": "15  Using a compilation",
    "section": "15.1 Output formats",
    "text": "15.1 Output formats"
  },
  {
    "objectID": "using_data.html#how-to-access-and-use-the-data",
    "href": "using_data.html#how-to-access-and-use-the-data",
    "title": "15  Using a compilation",
    "section": "15.2 How to access and use the data",
    "text": "15.2 How to access and use the data"
  },
  {
    "objectID": "tutorials.html",
    "href": "tutorials.html",
    "title": "16  Tutorials",
    "section": "",
    "text": "Following tutorials\n\ncreating a repository with template example"
  },
  {
    "objectID": "help.html#before-you-post",
    "href": "help.html#before-you-post",
    "title": "17  Help",
    "section": "17.1 Before you post",
    "text": "17.1 Before you post\n\nCode of conduct\nWhile this project is not part of ropensci, we will adopt their code of conduct. Please read it before engaging in discussion.\n\n\nSearch existing issues\nPlease check if your question already has an answer. You can search the [GitHub Repositories:\n\ntraits.build-book\ntraits.build\naustraits.build\n\n\n\nTry troubleshooting\nFor specific errors or other issues, please read this chapter’s section on troubleshooting. Please try to work through the steps yourself before posting a question."
  },
  {
    "objectID": "help.html#troubleshooting",
    "href": "help.html#troubleshooting",
    "title": "17  Help",
    "section": "17.2 Troubleshooting",
    "text": "17.2 Troubleshooting\nIt is okay to reach out if you are struggling to solve a specific problem in a specific project: an error message, a part of the code you are not sure how to write, or any experience with traits.build that is incorrect, unwelcome, unexpected, or confusing. However, please follow the guidelines below and take an active role in the troubleshooting process.\n\nUpdate your R packages\nIf the error is a bug in traits.build or austraits, it is possible the bug has already been fixed in a newer version. Before posting, please try again with the latest CRAN release of traits.build (or austraits), then again with the GitHub development version if needed. Please see http://traitecoevo.github.io/traits.build/#installation for installation instructions.\n\n\nAttribute the error\nThe traits.build package itself is often not usually the cause of problems that arise in traits.build pipelines. Most issues come from the user-defined R code, or data files that the pipeline calls, as well as other R packages on your system. So before you post a question, please attempt to troubleshoot and figure out if traits.build is actually the source of the trouble, or if the error comes from another package or your own code. The tips in the debugging chapter may help. If the culprit turns out to be a non-traits.build issue, then please ask your question in a non-traits.build forum and write the question accordingly.\n\n\nWrite a reprex\nTo set up the discussion for success, please provide the complete context of the problem, including a reprex. The purpose of a reprex, or reproducible example1, is to eliminate the knowledge gaps, misunderstandings, and hidden assumptions where bugs hide. A reprex is a sample of complete, self-contained, runnable code that fully emulates and reproduces the problem. The code should look clean and readable, be as short and concise as possible, run in as few seconds as possible, and contain only the details most relevant to troubleshooting. You can embed the code inline in your question, or you can upload it to a public repository and post the link. Regardless, please expect that anyone trying to help will read all the code and run the enclosed _targets.R file on their own private computer. This process is hands-on and empirical, so please make it as quick and easy as possible for the people who volunteer their valuable time and energy to answer questions.\nThe following posts explain how to write a good reprex.\n\nhttps://stackoverflow.com/help/minimal-reproducible-example\nhttps://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example\nhttps://reprex.tidyverse.org/\nhttps://www.tidyverse.org/blog/2017/12/workflow-vs-script/"
  },
  {
    "objectID": "help.html#sec-contact",
    "href": "help.html#sec-contact",
    "title": "17  Help",
    "section": "17.3 Contact",
    "text": "17.3 Contact\nThere are many ways to reach out.\n\nMaintainer\nTo contact the maintainer directly, please post to the relevant public GitHub Discussions page of the package.2 Examples:\n\ntraits.build: https://github.com/ropensci/targets/discussions\naustraits: https://github.com/ropensci/tarchetypes/discussions\n\nGitHub makes it easy to search for and link to public discussions. Not only does this help users solve their own problems, it also helps the maintainer avoid repetition. So please use discussions instead of private emails, instant messages, or mentions on social media."
  },
  {
    "objectID": "help.html#acknowledgements-and-copyright",
    "href": "help.html#acknowledgements-and-copyright",
    "title": "17  Help",
    "section": "17.4 Acknowledgements and copyright",
    "text": "17.4 Acknowledgements and copyright\nThis page was adapted from a corresponding file for the targets package, with text by Will Landau. The original file is available at https://github.com/ropensci-books/targets/blob/main/help.qmd. Text adapted from that page is under copy right specified in that package https://github.com/ropensci-books/targets/blob/main/LICENSE.md."
  },
  {
    "objectID": "help.html#footnotes",
    "href": "help.html#footnotes",
    "title": "17  Help",
    "section": "",
    "text": "Also known as a minimal reproducible example or minimal working example.↩︎\nYou may need to create a free GitHub account, but the process is straightforward.↩︎"
  },
  {
    "objectID": "troubleshooting.html#unsupported-trait-values",
    "href": "troubleshooting.html#unsupported-trait-values",
    "title": "18  Common issues",
    "section": "18.1 Unsupported trait values",
    "text": "18.1 Unsupported trait values\nThis error occurs when, for a categorical trait, the value in data.csv is different to the value in the traits dictionary (config/traits.yml).\n\ntable &lt;- my_database$excluded_data %&gt;%\n  filter(dataset_id == current_study) %&gt;%\n  filter(error == \"Unsupported trait value\") %&gt;%\n  select(dataset_id, trait_name, value) %&gt;%\n  distinct()\n\nYou can individually add substitutions to metadata.yml using the function metadata_add_substitution\n\nmetadata_add_substitution(dataset_id = current_study, trait_name = \"plant_growth_form\", find = \"T\", replace = \"tree\")\n\nOr, you can add an additional column to the table output (code above) and read it into metadata.yml using the function metadata_add_substitutions_table\nThe table read in must have the columns dataset_id, trait_name, find, and replace.\nThis is a hypothetical example for a table that contains 5 rows with plant_growth_form value that need updating.\n\ntable &lt;- table %&gt;%\n  rename(find = value) %&gt;%\n  mutate(replace = c(\"tree\", \"mallee\", \"shrub\", \"graminoid\", \"herb\"))\n\nmetadata_add_substitutions_table(table, dataset_id = dataset_id, trait_name = trait_name, find = find, replace = replace)\n\nYou can of course also write the table to a csv file, edit it in Excel or a text editor, then read it back into R.\n\nwrite_csv(table, \"data/dataset_id/raw/substitutions_required.csv\")\n\n...edit outside of R\n\ntable &lt;- read_csv(\"data/dataset_id/raw/substitutions_required.csv\")"
  },
  {
    "objectID": "troubleshooting.html#dataset-cant-pivot-wider",
    "href": "troubleshooting.html#dataset-cant-pivot-wider",
    "title": "18  Common issues",
    "section": "18.2 Dataset can’t pivot wider",
    "text": "18.2 Dataset can’t pivot wider\nIn order to convert a traits.build database into a wide format, the traits.build$traits table must be able to pivot wider. This dataset was unable to pivot, due to duplication in the following rows:\n\nmy_database$traits %&gt;%\n  filter(dataset_id == dataset_ids) %&gt;%\n  select(\n      dplyr::all_of(c(\"dataset_id\", \"trait_name\", \"value\", \"observation_id\", \"source_id\", \"taxon_name\",\n      \"entity_type\", \"life_stage\", \"basis_of_record\", \"value_type\", \"population_id\", \"individual_id\",\n      \"temporal_id\", \"method_id\", \"method_context_id\", \"entity_context_id\", \"original_name\"))\n          )\n  pivot_wider(names_from = trait_name, values_from = value, values_fn = length) %&gt;%\n  pivot_longer(cols = 16:ncol(.)) %&gt;%\n  rename(trait_name = name, number_of_duplicates = value) %&gt;%\n  select(dataset_id, taxon_name, trait_name, number_of_duplicates, observation_id, entity_type, value_type, population_id, everything()) %&gt;%\n  filter(number_of_duplicates &gt; 1)\n\nThere are two likely explanations – and solutions – to this error:\n\nIf your dataset combines individual (or population) level measurements with species-level measurements, the same species-level measurement may be read in many times. To solve this problem, you need to retain only the first instance of each species-level measurement, by including the following custom_R_code, where taxon_name is the column that contains taxon names and column 1, column 2, etc is a vector of the columns with categorical traits that require de-duplicating.\n\n\ndata %&gt;%\n  group_by(taxon_name) %&gt;%\n  mutate(across(c(\"column 1\", \"column 2\", \"column 3\"), replace_duplicates_with_NA))\n  ungroup()\n\n\nRows of data that represent measurements made at different times,\n\n… TBC"
  },
  {
    "objectID": "debugging.html",
    "href": "debugging.html",
    "title": "19  Debugging",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee @knuth84 for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "csv.html",
    "href": "csv.html",
    "title": "Appendix A — CSV files",
    "section": "",
    "text": "A comma-separated values (CSV) file is a delimited text file that uses a comma to separate values. Each line of the file is a data record. Each record consists of one or more fields, separated by commas. This is a comma format for storing tables of data in a simple text file. You can edit it in Excel or in a text editor. For more, see here."
  },
  {
    "objectID": "yaml.html",
    "href": "yaml.html",
    "title": "Appendix B — Yaml files",
    "section": "",
    "text": "The yml file extension (pronounced “YAML”) is a type structured data file, that is both human and machine readable. You can edit it in any text editor, or also in Rstudio. Generally, yml is used in situations where a table is not suitable because of variable lengths and or nested structures. It has the advantage over a spreadsheet in that the nested “headers” can have variable numbers of categories. The data under each of the hierarchical headings are easily extracted by R."
  }
]